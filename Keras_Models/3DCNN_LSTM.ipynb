{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9125bed-4143-4688-ac9f-ad5b1022be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv3D, MaxPooling3D,Conv2D,AveragePooling2D,AveragePooling3D\n",
    "from keras.layers import Dense, GlobalAveragePooling3D,GlobalAveragePooling2D\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler,ReduceLROnPlateau\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import ConvLSTM2D\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc73901d-914c-45e3-9ffd-d62ac597181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_path = 'Jester_Dataset/Dataset'\n",
    "Jester_data = pd.read_csv(os.path.join(cd_path,'Train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e2ac51d-09e1-4b49-bc52-b96b2e74766c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>frames</th>\n",
       "      <th>label_id</th>\n",
       "      <th>shape</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Doing other things</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Pushing Two Fingers Away</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Drumming Fingers</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>Sliding Two Fingers Down</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>Pushing Hand Away</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id                     label  frames  label_id       shape format\n",
       "0         1        Doing other things      37         0  (100, 176)   JPEG\n",
       "1         3  Pushing Two Fingers Away      37         6  (100, 176)   JPEG\n",
       "2         6          Drumming Fingers      37         1  (100, 176)   JPEG\n",
       "3        11  Sliding Two Fingers Down      37        10  (100, 176)   JPEG\n",
       "4        14         Pushing Hand Away      37         5  (100, 176)   JPEG"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jester_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3adbcc83-df91-46c0-97e1-24e760076fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "unique_labels = Jester_data['label'].unique()\n",
    "print(len(unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "597ca25c-c302-4c95-97a8-8cedc0c13a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing other things\n",
      "Pushing Two Fingers Away\n",
      "Drumming Fingers\n",
      "Sliding Two Fingers Down\n",
      "Pushing Hand Away\n",
      "Shaking Hand\n",
      "Pulling Two Fingers In\n",
      "Stop Sign\n",
      "Zooming In With Two Fingers\n",
      "Sliding Two Fingers Up\n",
      "Zooming Out With Two Fingers\n",
      "Zooming In With Full Hand\n",
      "No gesture\n",
      "Swiping Right\n",
      "Thumb Down\n",
      "Rolling Hand Forward\n",
      "Pulling Hand In\n",
      "Zooming Out With Full Hand\n",
      "Swiping Left\n",
      "Rolling Hand Backward\n",
      "Turning Hand Counterclockwise\n",
      "Swiping Up\n",
      "Turning Hand Clockwise\n",
      "Sliding Two Fingers Left\n",
      "Swiping Down\n",
      "Thumb Up\n",
      "Sliding Two Fingers Right\n"
     ]
    }
   ],
   "source": [
    "for labels in unique_labels:\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97e953a9-482d-4871-aa56-9d76986f0503",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_gestures = [\"Rolling Hand Backward\", \"Rolling Hand Forward\",\"No gesture\", \"Swiping Left\", \"Swiping Right\", \"Stop Sign\", \"Thumb Up\",\"Thumb Down\", \"Zooming Out With Full Hand\",\"Zooming In With Full Hand\",\"Shaking Hand\",\"Drumming Fingers\",\"Swiping Up\",\"Swiping Down\",\"Sliding Two Fingers Down\"]\n",
    "# selected_gestures = [\"Rolling Hand Backward\", \"Rolling Hand Forward\",\"No gesture\", \"Swiping Left\", \"Swiping Right\", \"Stop Sign\", \"Thumb Up\",\"Thumb Down\", \"Shaking Hand\",\"Drumming Fingers\",\"Swiping Up\",\"Swiping Down\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11a3d9ee-1467-4bcc-8de6-64a96d020969",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Jester_data[Jester_data['label'].isin(selected_gestures)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9073e55b-f728-41c4-9d0a-40aa67dcf069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>frames</th>\n",
       "      <th>label_id</th>\n",
       "      <th>shape</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50411</th>\n",
       "      <td>148075</td>\n",
       "      <td>No gesture</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50412</th>\n",
       "      <td>148077</td>\n",
       "      <td>Drumming Fingers</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50415</th>\n",
       "      <td>148084</td>\n",
       "      <td>No gesture</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50416</th>\n",
       "      <td>148085</td>\n",
       "      <td>Drumming Fingers</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50418</th>\n",
       "      <td>148090</td>\n",
       "      <td>Swiping Left</td>\n",
       "      <td>37</td>\n",
       "      <td>16</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       video_id             label  frames  label_id       shape format\n",
       "50411    148075        No gesture      37         2  (100, 176)   JPEG\n",
       "50412    148077  Drumming Fingers      37         1  (100, 176)   JPEG\n",
       "50415    148084        No gesture      37         2  (100, 176)   JPEG\n",
       "50416    148085  Drumming Fingers      37         1  (100, 176)   JPEG\n",
       "50418    148090      Swiping Left      37        16  (100, 176)   JPEG"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23e8f659-b2ce-4fe9-b115-19e22cd83ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "unique_labels = data['label'].unique()\n",
    "print(len(unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e4c7ee2-c309-4ba3-8f56-52ec4a0232dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drumming Fingers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sliding Two Fingers Down</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shaking Hand</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stop Sign</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Shaking Hand</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50411</th>\n",
       "      <td>No gesture</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50412</th>\n",
       "      <td>Drumming Fingers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50415</th>\n",
       "      <td>No gesture</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50416</th>\n",
       "      <td>Drumming Fingers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50418</th>\n",
       "      <td>Swiping Left</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26973 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          label  label_id\n",
       "2              Drumming Fingers         1\n",
       "3      Sliding Two Fingers Down        10\n",
       "5                  Shaking Hand         9\n",
       "8                     Stop Sign        14\n",
       "12                 Shaking Hand         9\n",
       "...                         ...       ...\n",
       "50411                No gesture         2\n",
       "50412          Drumming Fingers         1\n",
       "50415                No gesture         2\n",
       "50416          Drumming Fingers         1\n",
       "50418              Swiping Left        16\n",
       "\n",
       "[26973 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['label','label_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f74b0ee-f09e-4dbc-903d-0df9090fadc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1715"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['label']=='Rolling Hand Backward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9106f1e-6a5e-428c-852c-c0fad83cd866",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 128,128\n",
    "X_tr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c405e17-c5b7-493f-b45f-fdede2660c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>frames</th>\n",
       "      <th>label_id</th>\n",
       "      <th>shape</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>133</td>\n",
       "      <td>Rolling Hand Backward</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>201</td>\n",
       "      <td>Rolling Hand Backward</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>306</td>\n",
       "      <td>Rolling Hand Backward</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>405</td>\n",
       "      <td>Rolling Hand Backward</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>408</td>\n",
       "      <td>Rolling Hand Backward</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>(100, 132)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     video_id                  label  frames  label_id       shape format\n",
       "46        133  Rolling Hand Backward      37         7  (100, 176)   JPEG\n",
       "78        201  Rolling Hand Backward      37         7  (100, 176)   JPEG\n",
       "115       306  Rolling Hand Backward      37         7  (100, 176)   JPEG\n",
       "148       405  Rolling Hand Backward      37         7  (100, 176)   JPEG\n",
       "150       408  Rolling Hand Backward      37         7  (100, 132)   JPEG"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_label = 'Rolling Hand Backward'\n",
    "filtered_data = data[data['label']== desired_label]\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "376d4e08-7b4a-4447-affd-94be6037175c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1715it [00:08, 213.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 128, 128, 3)\n",
      "1715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(filtered_data.iterrows()): # Looping throgh all the subfolders \n",
    "    video_id = row['video_id']  # Name of the Video folder\n",
    "    video_path = os.path.join(cd_path,'Train',str(video_id)) # Path to the video folder\n",
    "\n",
    "    listing_stop = sorted(os.listdir(video_path))\n",
    "    frames = []\n",
    "    img_depth = 0\n",
    "\n",
    "    for imgs in listing_stop: # Looping through the images of the folder\n",
    "        if img_depth < 30:\n",
    "            img = os.path.join(video_path, imgs)\n",
    "            frame = cv2.imread(img)\n",
    "            # cv2.imshow(\"image\",frame)\n",
    "            frame = cv2.resize(frame, (img_rows, img_cols), interpolation=cv2.INTER_AREA)\n",
    "            RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(RGB)\n",
    "            img_depth += 1\n",
    "        else:\n",
    "            break\n",
    "        # Visualizing the dataset\n",
    "        # key = cv2.waitKey(1) & 0xFF\n",
    "        # if key == ord(\"q\"):\n",
    "        #     break\n",
    "    input_img = np.array(frames) # Converting to numpy arrays\n",
    "    # Converting \n",
    "    ipt = np.rollaxis(np.rollaxis(input_img, 2, 0), 2, 0)\n",
    "    ipt = np.rollaxis(ipt, 2, 0)\n",
    "    X_tr.append(ipt)\n",
    "# Shape and number of samples\n",
    "print(ipt.shape)\n",
    "num_samples = len(X_tr)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac34f08b-ec1a-4b8e-b53a-40f0825a5fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>frames</th>\n",
       "      <th>label_id</th>\n",
       "      <th>shape</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>56</td>\n",
       "      <td>Rolling Hand Forward</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>155</td>\n",
       "      <td>Rolling Hand Forward</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>212</td>\n",
       "      <td>Rolling Hand Forward</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>301</td>\n",
       "      <td>Rolling Hand Forward</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>316</td>\n",
       "      <td>Rolling Hand Forward</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     video_id                 label  frames  label_id       shape format\n",
       "18         56  Rolling Hand Forward      37         8  (100, 176)   JPEG\n",
       "56        155  Rolling Hand Forward      37         8  (100, 176)   JPEG\n",
       "81        212  Rolling Hand Forward      37         8  (100, 176)   JPEG\n",
       "111       301  Rolling Hand Forward      37         8  (100, 176)   JPEG\n",
       "119       316  Rolling Hand Forward      37         8  (100, 176)   JPEG"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_label = 'Rolling Hand Forward'\n",
    "filtered_data = data[data['label']== desired_label]\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c20eb736-db2e-42d0-a90c-9ef26ec3f08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1788it [00:19, 91.53it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 128, 128, 3)\n",
      "3503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(filtered_data.iterrows()): # Looping throgh all the subfolders \n",
    "    video_id = row['video_id']  # Name of the Video folder\n",
    "    video_path = os.path.join(cd_path,'Train',str(video_id)) # Path to the video folder\n",
    "\n",
    "    listing_stop = sorted(os.listdir(video_path))\n",
    "    frames = []\n",
    "    img_depth = 0\n",
    "\n",
    "    for imgs in listing_stop: # Looping through the images of the folder\n",
    "        if img_depth < 30:\n",
    "            img = os.path.join(video_path, imgs)\n",
    "            frame = cv2.imread(img)\n",
    "            # cv2.imshow(\"image\",frame)\n",
    "            frame = cv2.resize(frame, (img_rows, img_cols), interpolation=cv2.INTER_AREA)\n",
    "            RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(RGB)\n",
    "            img_depth += 1\n",
    "        else:\n",
    "            break\n",
    "        # Visualizing the dataset\n",
    "        # key = cv2.waitKey(1) & 0xFF\n",
    "        # if key == ord(\"q\"):\n",
    "        #     break\n",
    "    input_img = np.array(frames) # Converting to numpy arrays\n",
    "    # Converting \n",
    "    ipt = np.rollaxis(np.rollaxis(input_img, 2, 0), 2, 0)\n",
    "    ipt = np.rollaxis(ipt, 2, 0)\n",
    "    X_tr.append(ipt)\n",
    "# Shape and number of samples\n",
    "print(ipt.shape)\n",
    "num_samples = len(X_tr)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ac9bfa2-fff9-49c5-8962-7af7d7aa2347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>frames</th>\n",
       "      <th>label_id</th>\n",
       "      <th>shape</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50</td>\n",
       "      <td>No gesture</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>70</td>\n",
       "      <td>No gesture</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>161</td>\n",
       "      <td>No gesture</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>220</td>\n",
       "      <td>No gesture</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>314</td>\n",
       "      <td>No gesture</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>(100, 132)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     video_id       label  frames  label_id       shape format\n",
       "15         50  No gesture      37         2  (100, 176)   JPEG\n",
       "24         70  No gesture      37         2  (100, 176)   JPEG\n",
       "60        161  No gesture      37         2  (100, 176)   JPEG\n",
       "83        220  No gesture      37         2  (100, 176)   JPEG\n",
       "118       314  No gesture      37         2  (100, 132)   JPEG"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_label = 'No gesture'\n",
    "filtered_data = data[data['label']== desired_label]\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "477cea6e-25ae-4648-8dbf-9eb892667418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1844it [00:19, 96.53it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 128, 128, 3)\n",
      "5347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(filtered_data.iterrows()): # Looping throgh all the subfolders \n",
    "    video_id = row['video_id']  # Name of the Video folder\n",
    "    video_path = os.path.join(cd_path,'Train',str(video_id)) # Path to the video folder\n",
    "\n",
    "    listing_stop = sorted(os.listdir(video_path))\n",
    "    frames = []\n",
    "    img_depth = 0\n",
    "\n",
    "    for imgs in listing_stop: # Looping through the images of the folder\n",
    "        if img_depth < 30:\n",
    "            img = os.path.join(video_path, imgs)\n",
    "            frame = cv2.imread(img)\n",
    "            # cv2.imshow(\"image\",frame)\n",
    "            frame = cv2.resize(frame, (img_rows, img_cols), interpolation=cv2.INTER_AREA)\n",
    "            RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(RGB)\n",
    "            img_depth += 1\n",
    "        else:\n",
    "            break\n",
    "        # Visualizing the dataset\n",
    "        # key = cv2.waitKey(1) & 0xFF\n",
    "        # if key == ord(\"q\"):\n",
    "        #     break\n",
    "    input_img = np.array(frames) # Converting to numpy arrays\n",
    "    # Converting \n",
    "    ipt = np.rollaxis(np.rollaxis(input_img, 2, 0), 2, 0)\n",
    "    ipt = np.rollaxis(ipt, 2, 0)\n",
    "    X_tr.append(ipt)\n",
    "# Shape and number of samples\n",
    "print(ipt.shape)\n",
    "num_samples = len(X_tr)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e1745cf-90d8-4367-8c69-e1c222b1ec82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>frames</th>\n",
       "      <th>label_id</th>\n",
       "      <th>shape</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>107</td>\n",
       "      <td>Swiping Left</td>\n",
       "      <td>37</td>\n",
       "      <td>16</td>\n",
       "      <td>(100, 100)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>169</td>\n",
       "      <td>Swiping Left</td>\n",
       "      <td>37</td>\n",
       "      <td>16</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>327</td>\n",
       "      <td>Swiping Left</td>\n",
       "      <td>37</td>\n",
       "      <td>16</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>429</td>\n",
       "      <td>Swiping Left</td>\n",
       "      <td>37</td>\n",
       "      <td>16</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>477</td>\n",
       "      <td>Swiping Left</td>\n",
       "      <td>37</td>\n",
       "      <td>16</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     video_id         label  frames  label_id       shape format\n",
       "39        107  Swiping Left      37        16  (100, 100)   JPEG\n",
       "63        169  Swiping Left      37        16  (100, 176)   JPEG\n",
       "122       327  Swiping Left      37        16  (100, 176)   JPEG\n",
       "157       429  Swiping Left      37        16  (100, 176)   JPEG\n",
       "174       477  Swiping Left      37        16  (100, 176)   JPEG"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_label = 'Swiping Left'\n",
    "filtered_data = data[data['label']== desired_label]\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51cf4f81-7554-496c-9ef8-86bc83a26bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1762it [00:18, 95.74it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 128, 128, 3)\n",
      "7109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(filtered_data.iterrows()): # Looping throgh all the subfolders \n",
    "    video_id = row['video_id']  # Name of the Video folder\n",
    "    video_path = os.path.join(cd_path,'Train',str(video_id)) # Path to the video folder\n",
    "\n",
    "    listing_stop = sorted(os.listdir(video_path))\n",
    "    frames = []\n",
    "    img_depth = 0\n",
    "\n",
    "    for imgs in listing_stop: # Looping through the images of the folder\n",
    "        if img_depth < 30:\n",
    "            img = os.path.join(video_path, imgs)\n",
    "            frame = cv2.imread(img)\n",
    "            # cv2.imshow(\"image\",frame)\n",
    "            frame = cv2.resize(frame, (img_rows, img_cols), interpolation=cv2.INTER_AREA)\n",
    "            RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(RGB)\n",
    "            img_depth += 1\n",
    "        else:\n",
    "            break\n",
    "        # Visualizing the dataset\n",
    "        # key = cv2.waitKey(1) & 0xFF\n",
    "        # if key == ord(\"q\"):\n",
    "        #     break\n",
    "    input_img = np.array(frames) # Converting to numpy arrays\n",
    "    # Converting \n",
    "    ipt = np.rollaxis(np.rollaxis(input_img, 2, 0), 2, 0)\n",
    "    ipt = np.rollaxis(ipt, 2, 0)\n",
    "    X_tr.append(ipt)\n",
    "# Shape and number of samples\n",
    "print(ipt.shape)\n",
    "num_samples = len(X_tr)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5f9007e-a0fe-478a-9732-313f71f03dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>frames</th>\n",
       "      <th>label_id</th>\n",
       "      <th>shape</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>51</td>\n",
       "      <td>Swiping Right</td>\n",
       "      <td>37</td>\n",
       "      <td>17</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>95</td>\n",
       "      <td>Swiping Right</td>\n",
       "      <td>37</td>\n",
       "      <td>17</td>\n",
       "      <td>(100, 132)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>100</td>\n",
       "      <td>Swiping Right</td>\n",
       "      <td>37</td>\n",
       "      <td>17</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>149</td>\n",
       "      <td>Swiping Right</td>\n",
       "      <td>37</td>\n",
       "      <td>17</td>\n",
       "      <td>(100, 132)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>297</td>\n",
       "      <td>Swiping Right</td>\n",
       "      <td>37</td>\n",
       "      <td>17</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     video_id          label  frames  label_id       shape format\n",
       "16         51  Swiping Right      37        17  (100, 176)   JPEG\n",
       "34         95  Swiping Right      37        17  (100, 132)   JPEG\n",
       "35        100  Swiping Right      37        17  (100, 176)   JPEG\n",
       "52        149  Swiping Right      37        17  (100, 132)   JPEG\n",
       "110       297  Swiping Right      37        17  (100, 176)   JPEG"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_label = 'Swiping Right'\n",
    "filtered_data = data[data['label']== desired_label]\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "102ff784-3553-4c94-8a4c-8a0fa90c5c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1730it [00:18, 94.05it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 128, 128, 3)\n",
      "8839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(filtered_data.iterrows()): # Looping throgh all the subfolders \n",
    "    video_id = row['video_id']  # Name of the Video folder\n",
    "    video_path = os.path.join(cd_path,'Train',str(video_id)) # Path to the video folder\n",
    "\n",
    "    listing_stop = sorted(os.listdir(video_path))\n",
    "    frames = []\n",
    "    img_depth = 0\n",
    "\n",
    "    for imgs in listing_stop: # Looping through the images of the folder\n",
    "        if img_depth < 30:\n",
    "            img = os.path.join(video_path, imgs)\n",
    "            frame = cv2.imread(img)\n",
    "            # cv2.imshow(\"image\",frame)\n",
    "            frame = cv2.resize(frame, (img_rows, img_cols), interpolation=cv2.INTER_AREA)\n",
    "            RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(RGB)\n",
    "            img_depth += 1\n",
    "        else:\n",
    "            break\n",
    "        # Visualizing the dataset\n",
    "        # key = cv2.waitKey(1) & 0xFF\n",
    "        # if key == ord(\"q\"):\n",
    "        #     break\n",
    "    input_img = np.array(frames) # Converting to numpy arrays\n",
    "    # Converting \n",
    "    ipt = np.rollaxis(np.rollaxis(input_img, 2, 0), 2, 0)\n",
    "    ipt = np.rollaxis(ipt, 2, 0)\n",
    "    X_tr.append(ipt)\n",
    "# Shape and number of samples\n",
    "print(ipt.shape)\n",
    "num_samples = len(X_tr)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55fbe61c-ee64-4fbe-af91-0e814458a38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>frames</th>\n",
       "      <th>label_id</th>\n",
       "      <th>shape</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31</td>\n",
       "      <td>Stop Sign</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>59</td>\n",
       "      <td>Stop Sign</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>141</td>\n",
       "      <td>Stop Sign</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>145</td>\n",
       "      <td>Stop Sign</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>159</td>\n",
       "      <td>Stop Sign</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    video_id      label  frames  label_id       shape format\n",
       "8         31  Stop Sign      37        14  (100, 176)   JPEG\n",
       "20        59  Stop Sign      37        14  (100, 176)   JPEG\n",
       "50       141  Stop Sign      37        14  (100, 176)   JPEG\n",
       "51       145  Stop Sign      37        14  (100, 176)   JPEG\n",
       "58       159  Stop Sign      37        14  (100, 176)   JPEG"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_label = 'Stop Sign'\n",
    "filtered_data = data[data['label']== desired_label]\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d382e1e7-bf2b-43f0-bcf0-6d72d98322e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1821it [00:18, 99.61it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 128, 128, 3)\n",
      "10660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(filtered_data.iterrows()): # Looping throgh all the subfolders \n",
    "    video_id = row['video_id']  # Name of the Video folder\n",
    "    video_path = os.path.join(cd_path,'Train',str(video_id)) # Path to the video folder\n",
    "\n",
    "    listing_stop = sorted(os.listdir(video_path))\n",
    "    frames = []\n",
    "    img_depth = 0\n",
    "\n",
    "    for imgs in listing_stop: # Looping through the images of the folder\n",
    "        if img_depth < 30:\n",
    "            img = os.path.join(video_path, imgs)\n",
    "            frame = cv2.imread(img)\n",
    "            # cv2.imshow(\"image\",frame)\n",
    "            frame = cv2.resize(frame, (img_rows, img_cols), interpolation=cv2.INTER_AREA)\n",
    "            RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(RGB)\n",
    "            img_depth += 1\n",
    "        else:\n",
    "            break\n",
    "        # Visualizing the dataset\n",
    "        # key = cv2.waitKey(1) & 0xFF\n",
    "        # if key == ord(\"q\"):\n",
    "        #     break\n",
    "    input_img = np.array(frames) # Converting to numpy arrays\n",
    "    # Converting \n",
    "    ipt = np.rollaxis(np.rollaxis(input_img, 2, 0), 2, 0)\n",
    "    ipt = np.rollaxis(ipt, 2, 0)\n",
    "    X_tr.append(ipt)\n",
    "# Shape and number of samples\n",
    "print(ipt.shape)\n",
    "num_samples = len(X_tr)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4f57d46-0ef2-4315-b3b9-ff2a8653df54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>frames</th>\n",
       "      <th>label_id</th>\n",
       "      <th>shape</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>310</td>\n",
       "      <td>Thumb Up</td>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>381</td>\n",
       "      <td>Thumb Up</td>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>681</td>\n",
       "      <td>Thumb Up</td>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>718</td>\n",
       "      <td>Thumb Up</td>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>759</td>\n",
       "      <td>Thumb Up</td>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     video_id     label  frames  label_id       shape format\n",
       "116       310  Thumb Up      37        20  (100, 176)   JPEG\n",
       "139       381  Thumb Up      37        20  (100, 176)   JPEG\n",
       "256       681  Thumb Up      37        20  (100, 176)   JPEG\n",
       "271       718  Thumb Up      37        20  (100, 176)   JPEG\n",
       "289       759  Thumb Up      37        20  (100, 176)   JPEG"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_label = 'Thumb Up'\n",
    "filtered_data = data[data['label']== desired_label]\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4dff133e-c368-4b93-bc14-5e1ad9ea7945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1841it [00:19, 93.47it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 128, 128, 3)\n",
      "12501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(filtered_data.iterrows()): # Looping throgh all the subfolders \n",
    "    video_id = row['video_id']  # Name of the Video folder\n",
    "    video_path = os.path.join(cd_path,'Train',str(video_id)) # Path to the video folder\n",
    "\n",
    "    listing_stop = sorted(os.listdir(video_path))\n",
    "    frames = []\n",
    "    img_depth = 0\n",
    "\n",
    "    for imgs in listing_stop: # Looping through the images of the folder\n",
    "        if img_depth < 30:\n",
    "            img = os.path.join(video_path, imgs)\n",
    "            frame = cv2.imread(img)\n",
    "            # cv2.imshow(\"image\",frame)\n",
    "            frame = cv2.resize(frame, (img_rows, img_cols), interpolation=cv2.INTER_AREA)\n",
    "            RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(RGB)\n",
    "            img_depth += 1\n",
    "        else:\n",
    "            break\n",
    "        # Visualizing the dataset\n",
    "        # key = cv2.waitKey(1) & 0xFF\n",
    "        # if key == ord(\"q\"):\n",
    "        #     break\n",
    "    input_img = np.array(frames) # Converting to numpy arrays\n",
    "    # Converting \n",
    "    ipt = np.rollaxis(np.rollaxis(input_img, 2, 0), 2, 0)\n",
    "    ipt = np.rollaxis(ipt, 2, 0)\n",
    "    X_tr.append(ipt)\n",
    "# Shape and number of samples\n",
    "print(ipt.shape)\n",
    "num_samples = len(X_tr)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b948ae4-14db-40f7-aa91-9eee5a8728af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>frames</th>\n",
       "      <th>label_id</th>\n",
       "      <th>shape</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>55</td>\n",
       "      <td>Thumb Down</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>160</td>\n",
       "      <td>Thumb Down</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>(100, 132)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>193</td>\n",
       "      <td>Thumb Down</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>304</td>\n",
       "      <td>Thumb Down</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>331</td>\n",
       "      <td>Thumb Down</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     video_id       label  frames  label_id       shape format\n",
       "17         55  Thumb Down      37        19  (100, 176)   JPEG\n",
       "59        160  Thumb Down      37        19  (100, 132)   JPEG\n",
       "73        193  Thumb Down      37        19  (100, 176)   JPEG\n",
       "113       304  Thumb Down      37        19  (100, 176)   JPEG\n",
       "124       331  Thumb Down      37        19  (100, 176)   JPEG"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_label = 'Thumb Down'\n",
    "filtered_data = data[data['label']== desired_label]\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c2aa9f0-7ed8-416b-b4ee-fbdaa2695bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1810it [00:20, 90.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 128, 128, 3)\n",
      "14311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(filtered_data.iterrows()): # Looping throgh all the subfolders \n",
    "    video_id = row['video_id']  # Name of the Video folder\n",
    "    video_path = os.path.join(cd_path,'Train',str(video_id)) # Path to the video folder\n",
    "\n",
    "    listing_stop = sorted(os.listdir(video_path))\n",
    "    frames = []\n",
    "    img_depth = 0\n",
    "\n",
    "    for imgs in listing_stop: # Looping through the images of the folder\n",
    "        if img_depth < 30:\n",
    "            img = os.path.join(video_path, imgs)\n",
    "            frame = cv2.imread(img)\n",
    "            # cv2.imshow(\"image\",frame)\n",
    "            frame = cv2.resize(frame, (img_rows, img_cols), interpolation=cv2.INTER_AREA)\n",
    "            RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(RGB)\n",
    "            img_depth += 1\n",
    "        else:\n",
    "            break\n",
    "        # Visualizing the dataset\n",
    "        # key = cv2.waitKey(1) & 0xFF\n",
    "        # if key == ord(\"q\"):\n",
    "        #     break\n",
    "    input_img = np.array(frames) # Converting to numpy arrays\n",
    "    # Converting \n",
    "    ipt = np.rollaxis(np.rollaxis(input_img, 2, 0), 2, 0)\n",
    "    ipt = np.rollaxis(ipt, 2, 0)\n",
    "    X_tr.append(ipt)\n",
    "# Shape and number of samples\n",
    "print(ipt.shape)\n",
    "num_samples = len(X_tr)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d0b14f3-303d-44d9-b656-88f4420667e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>frames</th>\n",
       "      <th>label_id</th>\n",
       "      <th>shape</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>103</td>\n",
       "      <td>Zooming Out With Full Hand</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>110</td>\n",
       "      <td>Zooming Out With Full Hand</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>150</td>\n",
       "      <td>Zooming Out With Full Hand</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>302</td>\n",
       "      <td>Zooming Out With Full Hand</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>(100, 132)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>433</td>\n",
       "      <td>Zooming Out With Full Hand</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     video_id                       label  frames  label_id       shape format\n",
       "36        103  Zooming Out With Full Hand      37        25  (100, 176)   JPEG\n",
       "41        110  Zooming Out With Full Hand      37        25  (100, 176)   JPEG\n",
       "53        150  Zooming Out With Full Hand      37        25  (100, 176)   JPEG\n",
       "112       302  Zooming Out With Full Hand      37        25  (100, 132)   JPEG\n",
       "159       433  Zooming Out With Full Hand      37        25  (100, 176)   JPEG"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_label = 'Zooming Out With Full Hand'\n",
    "filtered_data = data[data['label']== desired_label]\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eff386dc-c608-4645-9dcf-cc647609a3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1832it [00:20, 90.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 128, 128, 3)\n",
      "16143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(filtered_data.iterrows()): # Looping throgh all the subfolders \n",
    "    video_id = row['video_id']  # Name of the Video folder\n",
    "    video_path = os.path.join(cd_path,'Train',str(video_id)) # Path to the video folder\n",
    "\n",
    "    listing_stop = sorted(os.listdir(video_path))\n",
    "    frames = []\n",
    "    img_depth = 0\n",
    "\n",
    "    for imgs in listing_stop: # Looping through the images of the folder\n",
    "        if img_depth < 30:\n",
    "            img = os.path.join(video_path, imgs)\n",
    "            frame = cv2.imread(img)\n",
    "            # cv2.imshow(\"image\",frame)\n",
    "            frame = cv2.resize(frame, (img_rows, img_cols), interpolation=cv2.INTER_AREA)\n",
    "            RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(RGB)\n",
    "            img_depth += 1\n",
    "        else:\n",
    "            break\n",
    "        # Visualizing the dataset\n",
    "        # key = cv2.waitKey(1) & 0xFF\n",
    "        # if key == ord(\"q\"):\n",
    "        #     break\n",
    "    input_img = np.array(frames) # Converting to numpy arrays\n",
    "    # Converting \n",
    "    ipt = np.rollaxis(np.rollaxis(input_img, 2, 0), 2, 0)\n",
    "    ipt = np.rollaxis(ipt, 2, 0)\n",
    "    X_tr.append(ipt)\n",
    "# Shape and number of samples\n",
    "print(ipt.shape)\n",
    "num_samples = len(X_tr)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7596c061-ce5e-4bde-96d8-834562dc8e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>frames</th>\n",
       "      <th>label_id</th>\n",
       "      <th>shape</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>46</td>\n",
       "      <td>Zooming In With Full Hand</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>167</td>\n",
       "      <td>Zooming In With Full Hand</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>(100, 132)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>171</td>\n",
       "      <td>Zooming In With Full Hand</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>194</td>\n",
       "      <td>Zooming In With Full Hand</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>197</td>\n",
       "      <td>Zooming In With Full Hand</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>(100, 132)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    video_id                      label  frames  label_id       shape format\n",
       "14        46  Zooming In With Full Hand      37        23  (100, 176)   JPEG\n",
       "62       167  Zooming In With Full Hand      37        23  (100, 132)   JPEG\n",
       "64       171  Zooming In With Full Hand      37        23  (100, 176)   JPEG\n",
       "74       194  Zooming In With Full Hand      37        23  (100, 176)   JPEG\n",
       "76       197  Zooming In With Full Hand      37        23  (100, 132)   JPEG"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_label = 'Zooming In With Full Hand'\n",
    "filtered_data = data[data['label']== desired_label]\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6dc10102-f612-4a80-9bc2-5444d7a94b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1799it [00:19, 94.34it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 128, 128, 3)\n",
      "17942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(filtered_data.iterrows()): # Looping throgh all the subfolders \n",
    "    video_id = row['video_id']  # Name of the Video folder\n",
    "    video_path = os.path.join(cd_path,'Train',str(video_id)) # Path to the video folder\n",
    "\n",
    "    listing_stop = sorted(os.listdir(video_path))\n",
    "    frames = []\n",
    "    img_depth = 0\n",
    "\n",
    "    for imgs in listing_stop: # Looping through the images of the folder\n",
    "        if img_depth < 30:\n",
    "            img = os.path.join(video_path, imgs)\n",
    "            frame = cv2.imread(img)\n",
    "            # cv2.imshow(\"image\",frame)\n",
    "            frame = cv2.resize(frame, (img_rows, img_cols), interpolation=cv2.INTER_AREA)\n",
    "            RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(RGB)\n",
    "            img_depth += 1\n",
    "        else:\n",
    "            break\n",
    "        # Visualizing the dataset\n",
    "        # key = cv2.waitKey(1) & 0xFF\n",
    "        # if key == ord(\"q\"):\n",
    "        #     break\n",
    "    input_img = np.array(frames) # Converting to numpy arrays\n",
    "    # Converting \n",
    "    ipt = np.rollaxis(np.rollaxis(input_img, 2, 0), 2, 0)\n",
    "    ipt = np.rollaxis(ipt, 2, 0)\n",
    "    X_tr.append(ipt)\n",
    "# Shape and number of samples\n",
    "print(ipt.shape)\n",
    "num_samples = len(X_tr)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93f6e833-4012-4aa2-843a-72969746125f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>frames</th>\n",
       "      <th>label_id</th>\n",
       "      <th>shape</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>Shaking Hand</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>41</td>\n",
       "      <td>Shaking Hand</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>137</td>\n",
       "      <td>Shaking Hand</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>263</td>\n",
       "      <td>Shaking Hand</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>580</td>\n",
       "      <td>Shaking Hand</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     video_id         label  frames  label_id       shape format\n",
       "5          17  Shaking Hand      37         9  (100, 176)   JPEG\n",
       "12         41  Shaking Hand      37         9  (100, 176)   JPEG\n",
       "47        137  Shaking Hand      37         9  (100, 176)   JPEG\n",
       "101       263  Shaking Hand      37         9  (100, 176)   JPEG\n",
       "224       580  Shaking Hand      37         9  (100, 176)   JPEG"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_label = 'Shaking Hand'\n",
    "filtered_data = data[data['label']== desired_label]\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8033da09-1d37-4e86-9344-d8ab3a248403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1789it [00:19, 92.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 128, 128, 3)\n",
      "19731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(filtered_data.iterrows()): # Looping throgh all the subfolders \n",
    "    video_id = row['video_id']  # Name of the Video folder\n",
    "    video_path = os.path.join(cd_path,'Train',str(video_id)) # Path to the video folder\n",
    "\n",
    "    listing_stop = sorted(os.listdir(video_path))\n",
    "    frames = []\n",
    "    img_depth = 0\n",
    "\n",
    "    for imgs in listing_stop: # Looping through the images of the folder\n",
    "        if img_depth < 30:\n",
    "            img = os.path.join(video_path, imgs)\n",
    "            frame = cv2.imread(img)\n",
    "            # cv2.imshow(\"image\",frame)\n",
    "            frame = cv2.resize(frame, (img_rows, img_cols), interpolation=cv2.INTER_AREA)\n",
    "            RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(RGB)\n",
    "            img_depth += 1\n",
    "        else:\n",
    "            break\n",
    "        # Visualizing the dataset\n",
    "        # key = cv2.waitKey(1) & 0xFF\n",
    "        # if key == ord(\"q\"):\n",
    "        #     break\n",
    "    input_img = np.array(frames) # Converting to numpy arrays\n",
    "    # Converting \n",
    "    ipt = np.rollaxis(np.rollaxis(input_img, 2, 0), 2, 0)\n",
    "    ipt = np.rollaxis(ipt, 2, 0)\n",
    "    X_tr.append(ipt)\n",
    "# Shape and number of samples\n",
    "print(ipt.shape)\n",
    "num_samples = len(X_tr)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb3792e6-c71e-45b4-af55-9c3d251fa99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>frames</th>\n",
       "      <th>label_id</th>\n",
       "      <th>shape</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Drumming Fingers</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>233</td>\n",
       "      <td>Drumming Fingers</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>294</td>\n",
       "      <td>Drumming Fingers</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>452</td>\n",
       "      <td>Drumming Fingers</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>498</td>\n",
       "      <td>Drumming Fingers</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     video_id             label  frames  label_id       shape format\n",
       "2           6  Drumming Fingers      37         1  (100, 176)   JPEG\n",
       "87        233  Drumming Fingers      37         1  (100, 176)   JPEG\n",
       "109       294  Drumming Fingers      37         1  (100, 176)   JPEG\n",
       "165       452  Drumming Fingers      37         1  (100, 176)   JPEG\n",
       "184       498  Drumming Fingers      37         1  (100, 176)   JPEG"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_label = 'Drumming Fingers'\n",
    "filtered_data = data[data['label']== desired_label]\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4a6db4c-24c7-430d-b53e-c933ea08974e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1818it [00:19, 92.81it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 128, 128, 3)\n",
      "21549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(filtered_data.iterrows()): # Looping throgh all the subfolders \n",
    "    video_id = row['video_id']  # Name of the Video folder\n",
    "    video_path = os.path.join(cd_path,'Train',str(video_id)) # Path to the video folder\n",
    "\n",
    "    listing_stop = sorted(os.listdir(video_path))\n",
    "    frames = []\n",
    "    img_depth = 0\n",
    "\n",
    "    for imgs in listing_stop: # Looping through the images of the folder\n",
    "        if img_depth < 30:\n",
    "            img = os.path.join(video_path, imgs)\n",
    "            frame = cv2.imread(img)\n",
    "            # cv2.imshow(\"image\",frame)\n",
    "            frame = cv2.resize(frame, (img_rows, img_cols), interpolation=cv2.INTER_AREA)\n",
    "            RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(RGB)\n",
    "            img_depth += 1\n",
    "        else:\n",
    "            break\n",
    "        # Visualizing the dataset\n",
    "        # key = cv2.waitKey(1) & 0xFF\n",
    "        # if key == ord(\"q\"):\n",
    "        #     break\n",
    "    input_img = np.array(frames) # Converting to numpy arrays\n",
    "    # Converting \n",
    "    ipt = np.rollaxis(np.rollaxis(input_img, 2, 0), 2, 0)\n",
    "    ipt = np.rollaxis(ipt, 2, 0)\n",
    "    X_tr.append(ipt)\n",
    "# Shape and number of samples\n",
    "print(ipt.shape)\n",
    "num_samples = len(X_tr)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a37f290a-7d41-4357-86c7-e584258e897a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>frames</th>\n",
       "      <th>label_id</th>\n",
       "      <th>shape</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>157</td>\n",
       "      <td>Swiping Up</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>217</td>\n",
       "      <td>Swiping Up</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>232</td>\n",
       "      <td>Swiping Up</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>(100, 132)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>250</td>\n",
       "      <td>Swiping Up</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>336</td>\n",
       "      <td>Swiping Up</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     video_id       label  frames  label_id       shape format\n",
       "57        157  Swiping Up      37        18  (100, 176)   JPEG\n",
       "82        217  Swiping Up      37        18  (100, 176)   JPEG\n",
       "86        232  Swiping Up      37        18  (100, 132)   JPEG\n",
       "96        250  Swiping Up      37        18  (100, 176)   JPEG\n",
       "126       336  Swiping Up      37        18  (100, 176)   JPEG"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_label = 'Swiping Up'\n",
    "filtered_data = data[data['label']== desired_label]\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7fa38b2-fd3f-4eee-a952-79377c2b032c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1768it [00:23, 76.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 128, 128, 3)\n",
      "23317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(filtered_data.iterrows()): # Looping throgh all the subfolders \n",
    "    video_id = row['video_id']  # Name of the Video folder\n",
    "    video_path = os.path.join(cd_path,'Train',str(video_id)) # Path to the video folder\n",
    "\n",
    "    listing_stop = sorted(os.listdir(video_path))\n",
    "    frames = []\n",
    "    img_depth = 0\n",
    "\n",
    "    for imgs in listing_stop: # Looping through the imges of the folder\n",
    "        if img_depth < 30:\n",
    "            img = os.path.join(video_path, imgs)\n",
    "            frame = cv2.imread(img)\n",
    "            # cv2.imshow(\"image\",frame)\n",
    "            frame = cv2.resize(frame, (img_rows, img_cols), interpolation=cv2.INTER_AREA)\n",
    "            RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(RGB)\n",
    "            img_depth += 1\n",
    "        else:\n",
    "            break\n",
    "        # Visualizing the dataset\n",
    "        # key = cv2.waitKey(1) & 0xFF\n",
    "        # if key == ord(\"q\"):\n",
    "        #     break\n",
    "    input_img = np.array(frames) # Converting to numpy arrays\n",
    "    # Converting \n",
    "    ipt = np.rollaxis(np.rollaxis(input_img, 2, 0), 2, 0)\n",
    "    ipt = np.rollaxis(ipt, 2, 0)\n",
    "    X_tr.append(ipt)\n",
    "# Shape and number of samples\n",
    "print(ipt.shape)\n",
    "num_samples = len(X_tr)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5dee2ec-9bee-4e0a-baec-c94e407de129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>frames</th>\n",
       "      <th>label_id</th>\n",
       "      <th>shape</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>196</td>\n",
       "      <td>Swiping Down</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>198</td>\n",
       "      <td>Swiping Down</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>248</td>\n",
       "      <td>Swiping Down</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>413</td>\n",
       "      <td>Swiping Down</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>497</td>\n",
       "      <td>Swiping Down</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     video_id         label  frames  label_id       shape format\n",
       "75        196  Swiping Down      37        15  (100, 176)   JPEG\n",
       "77        198  Swiping Down      37        15  (100, 176)   JPEG\n",
       "95        248  Swiping Down      37        15  (100, 176)   JPEG\n",
       "152       413  Swiping Down      37        15  (100, 176)   JPEG\n",
       "183       497  Swiping Down      37        15  (100, 176)   JPEG"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_label = 'Swiping Down'\n",
    "filtered_data = data[data['label']== desired_label]\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ef8722d-5c22-402d-8d43-2be783d546b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1824it [00:19, 94.60it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 128, 128, 3)\n",
      "25141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(filtered_data.iterrows()): # Looping throgh all the subfolders \n",
    "    video_id = row['video_id']  # Name of the Video folder\n",
    "    video_path = os.path.join(cd_path,'Train',str(video_id)) # Path to the video folder\n",
    "\n",
    "    listing_stop = sorted(os.listdir(video_path))\n",
    "    frames = []\n",
    "    img_depth = 0\n",
    "\n",
    "    for imgs in listing_stop: # Looping through the images of the folder\n",
    "        if img_depth < 30:\n",
    "            img = os.path.join(video_path, imgs)\n",
    "            frame = cv2.imread(img)\n",
    "            # cv2.imshow(\"image\",frame)\n",
    "            frame = cv2.resize(frame, (img_rows, img_cols), interpolation=cv2.INTER_AREA)\n",
    "            RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(RGB)\n",
    "            img_depth += 1\n",
    "        else:\n",
    "            break\n",
    "        # Visualizing the dataset\n",
    "        # key = cv2.waitKey(1) & 0xFF\n",
    "        # if key == ord(\"q\"):\n",
    "        #     break\n",
    "    input_img = np.array(frames) # Converting to numpy arrays\n",
    "    # Converting \n",
    "    ipt = np.rollaxis(np.rollaxis(input_img, 2, 0), 2, 0)\n",
    "    ipt = np.rollaxis(ipt, 2, 0)\n",
    "    X_tr.append(ipt)\n",
    "# Shape and number of samples\n",
    "print(ipt.shape)\n",
    "num_samples = len(X_tr)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "530fa322-8163-4ce1-be8f-c8f932f9f8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>frames</th>\n",
       "      <th>label_id</th>\n",
       "      <th>shape</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>Sliding Two Fingers Down</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>85</td>\n",
       "      <td>Sliding Two Fingers Down</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>(100, 100)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>121</td>\n",
       "      <td>Sliding Two Fingers Down</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>(100, 132)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>184</td>\n",
       "      <td>Sliding Two Fingers Down</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>(100, 132)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>330</td>\n",
       "      <td>Sliding Two Fingers Down</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>(100, 176)</td>\n",
       "      <td>JPEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     video_id                     label  frames  label_id       shape format\n",
       "3          11  Sliding Two Fingers Down      37        10  (100, 176)   JPEG\n",
       "30         85  Sliding Two Fingers Down      37        10  (100, 100)   JPEG\n",
       "44        121  Sliding Two Fingers Down      37        10  (100, 132)   JPEG\n",
       "69        184  Sliding Two Fingers Down      37        10  (100, 132)   JPEG\n",
       "123       330  Sliding Two Fingers Down      37        10  (100, 176)   JPEG"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_label = 'Sliding Two Fingers Down'\n",
    "filtered_data = data[data['label']== desired_label]\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1177854d-6de7-4d56-950e-99c5b46aafea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1832it [00:20, 88.39it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 128, 128, 3)\n",
      "26973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(filtered_data.iterrows()): # Looping throgh all the subfolders \n",
    "    video_id = row['video_id']  # Name of the Video folder\n",
    "    video_path = os.path.join(cd_path,'Train',str(video_id)) # Path to the video folder\n",
    "\n",
    "    listing_stop = sorted(os.listdir(video_path))\n",
    "    frames = []\n",
    "    img_depth = 0\n",
    "\n",
    "    for imgs in listing_stop: # Looping through the images of the folder\n",
    "        if img_depth < 30:\n",
    "            img = os.path.join(video_path, imgs)\n",
    "            frame = cv2.imread(img)\n",
    "            # cv2.imshow(\"image\",frame)\n",
    "            frame = cv2.resize(frame, (img_rows, img_cols), interpolation=cv2.INTER_AREA)\n",
    "            RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(RGB)\n",
    "            img_depth += 1\n",
    "        else:\n",
    "            break\n",
    "        # Visualizing the dataset\n",
    "        # key = cv2.waitKey(1) & 0xFF\n",
    "        # if key == ord(\"q\"):\n",
    "        #     break\n",
    "    input_img = np.array(frames) # Converting to numpy arrays\n",
    "    # Converting \n",
    "    ipt = np.rollaxis(np.rollaxis(input_img, 2, 0), 2, 0)\n",
    "    ipt = np.rollaxis(ipt, 2, 0)\n",
    "    X_tr.append(ipt)\n",
    "# Shape and number of samples\n",
    "print(ipt.shape)\n",
    "num_samples = len(X_tr)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e3803ca-4ffa-40cb-be1b-7e71670baad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1715\n"
     ]
    }
   ],
   "source": [
    "X_tr_array = np.array(X_tr)   # converting the frames read into array\n",
    "num_samples = len(X_tr_array) \n",
    "print (num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8070c79a-6d1a-4851-bb3a-841901158917",
   "metadata": {},
   "outputs": [],
   "source": [
    "label=np.ones((num_samples,),dtype = int)\n",
    "label[0:1715]= 0        # Rolling Hand Backward\n",
    "label[1715:3503] = 1    # Rolling Hand Forward\n",
    "label[3503:5347] = 2    # No gesture\n",
    "label[5347:7109] = 3    # Swiping Left\n",
    "label[7109:8839] = 4    # Swiping Right\n",
    "label[8839:10660] = 5   # Stop Sign\n",
    "label[10660:12501] = 6  # Thumb Up\n",
    "label[12501:14311] = 7  # Thumb Down\n",
    "label[14311:16143] = 8  # Zooming Out With Full Hand\n",
    "label[16143:17942] = 9  # Zooming In With Full Hand\n",
    "label[17942:19731] = 10 # Shaking Hand\n",
    "label[19731:21549] = 11 # Drumming Fingers\n",
    "label[21549:23317] = 12  # Swiping Up\n",
    "label[23317:25141] = 13 # Swiping Down\n",
    "label[25141:26973] = 14 # Sliding Two Fingers Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "984ce549-0923-41be-8973-5822a87480e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train shape: (1715, 10, 128, 128, 3)\n",
      "(1715, 10, 128, 128, 3) train samples\n"
     ]
    }
   ],
   "source": [
    "img_depth = 30\n",
    "train_data = [X_tr_array,label]\n",
    "(X_train, y_train) = (train_data[0],train_data[1])\n",
    "\n",
    "print('X_Train shape:', X_train.shape)\n",
    "train_set = np.zeros((num_samples, img_depth, img_cols,img_rows,3))\n",
    "\n",
    "for h in range(num_samples):\n",
    "    train_set[h][:][:][:][:]=X_train[h,:,:,:]\n",
    "\n",
    "patch_size = 30   # img_depth or number of frames used for each video\n",
    "print(train_set.shape, 'train samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c22ed553-065f-4d66-8273-883cddc406c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_classes = 15\n",
    "nb_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0316cc43-c2ab-44e8-814e-57ce85c84841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1715, 2)\n"
     ]
    }
   ],
   "source": [
    "Y_train = tensorflow.keras.utils.to_categorical(y_train, nb_classes)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d38f5612-d53a-4558-bbac-e67d961e3621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalization(Pre-Processing)\n",
    "# train_set = train_set.astype('float32')\n",
    "# print(np.mean(train_set))\n",
    "# train_set -= np.mean(train_set)\n",
    "# print(np.max(train_set))\n",
    "# train_set /=np.max(train_set)\n",
    "batch_size = 100  # Adjust this value as needed\n",
    "for i in range(0, len(train_set), batch_size):\n",
    "    batch = train_set[i:i+batch_size]\n",
    "    batch = batch.astype('float32')\n",
    "    batch -= np.mean(batch)\n",
    "    batch /= np.max(batch)\n",
    "    train_set[i:i+batch_size] = batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac20b896-6619-4fc5-b702-bb845b9349dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3DCNN + LSTM MODEL\n",
    "weight_decay = 0.00005\n",
    "l2=keras.regularizers.l2\n",
    "model = Sequential()\n",
    "model.add(Conv3D(16,(3,3,3),input_shape=(patch_size, img_cols, img_rows, 3),activation='relu'))\n",
    "model.add(Conv3D(16,(3,3,3), strides=(1,1,1),padding='same', dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, name='Conv3D_2a_a', activation = 'relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv3D(32,(3,3,3), strides=(1,1,1),padding='same', dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, name='Conv3D_2b_a', activation = 'relu'))\n",
    "model.add(Conv3D(32,(3,3,3), strides=(1,1,1),padding='same', dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, name='Conv3D_2b_b', activation = 'relu'))\n",
    "model.add(MaxPooling3D(pool_size=(1, 2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv3D(64,(3,3,3), strides=(1,1,1),padding='same',dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, name='Conv3D_2c_a', activation = 'relu'))\n",
    "model.add(Conv3D(64,(3,3,3), strides=(1,1,1),padding='same', dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, name='Conv3D_2c_b', activation = 'relu'))\n",
    "model.add(Conv3D(64,(3,3,3), strides=(1,1,1),padding='same', dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, name='Conv3D_2c_c', activation = 'relu'))\n",
    "model.add(MaxPooling3D(pool_size=(1, 2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv3D(128,(3,3,3), strides=(1,1,1),padding='same', dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, name='Conv3D_2d_a', activation = 'relu'))\n",
    "model.add(Conv3D(128,(3,3,3), strides=(1,1,1),padding='same', dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, name='Conv3D_2d_b', activation = 'relu'))\n",
    "model.add(Conv3D(128,(3,3,3), strides=(1,1,1),padding='same', dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, name='Conv3D_2d_c', activation = 'relu'))\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(3,3),strides=(1,1),padding='same',\n",
    "                      kernel_initializer='he_normal', recurrent_initializer='he_normal',\n",
    "                      kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay),\n",
    "                      return_sequences=True, name='gatedclstm2d_2'))\n",
    "\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(3,3),strides=(1,1),padding='same',\n",
    "                      kernel_initializer='he_normal', recurrent_initializer='he_normal',\n",
    "                      kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay),\n",
    "                      return_sequences=True, name='gatedclstm2d_3'))\n",
    "\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(3,3),strides=(1,1),padding='same',\n",
    "                      kernel_initializer='he_normal', recurrent_initializer='he_normal',\n",
    "                      kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay),\n",
    "                      return_sequences=True, name='gatedclstm2d_4'))\n",
    "#model.add(MaxPooling3D(pool_size=(nb_pool[0], nb_pool[0], nb_pool[0])))\n",
    "#model.add(Flatten())\n",
    "model.add(GlobalAveragePooling3D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes,kernel_initializer='normal'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fe0842d-a7f0-4000-9887-c61b0a5f967f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_1 (Conv3D)           (None, 8, 126, 126, 16)   1312      \n",
      "                                                                 \n",
      " Conv3D_2a_a (Conv3D)        (None, 8, 126, 126, 16)   6912      \n",
      "                                                                 \n",
      " max_pooling3d_4 (MaxPoolin  (None, 4, 63, 63, 16)     0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " Conv3D_2b_a (Conv3D)        (None, 4, 63, 63, 32)     13824     \n",
      "                                                                 \n",
      " Conv3D_2b_b (Conv3D)        (None, 4, 63, 63, 32)     27648     \n",
      "                                                                 \n",
      " max_pooling3d_5 (MaxPoolin  (None, 4, 31, 31, 32)     0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " Conv3D_2c_a (Conv3D)        (None, 4, 31, 31, 64)     55296     \n",
      "                                                                 \n",
      " Conv3D_2c_b (Conv3D)        (None, 4, 31, 31, 64)     110592    \n",
      "                                                                 \n",
      " Conv3D_2c_c (Conv3D)        (None, 4, 31, 31, 64)     110592    \n",
      "                                                                 \n",
      " max_pooling3d_6 (MaxPoolin  (None, 4, 15, 15, 64)     0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " Conv3D_2d_a (Conv3D)        (None, 4, 15, 15, 128)    221184    \n",
      "                                                                 \n",
      " Conv3D_2d_b (Conv3D)        (None, 4, 15, 15, 128)    442368    \n",
      "                                                                 \n",
      " Conv3D_2d_c (Conv3D)        (None, 4, 15, 15, 128)    442368    \n",
      "                                                                 \n",
      " max_pooling3d_7 (MaxPoolin  (None, 4, 7, 7, 128)      0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " gatedclstm2d_2 (ConvLSTM2D  (None, 4, 7, 7, 64)       442624    \n",
      " )                                                               \n",
      "                                                                 \n",
      " gatedclstm2d_3 (ConvLSTM2D  (None, 4, 7, 7, 64)       295168    \n",
      " )                                                               \n",
      "                                                                 \n",
      " gatedclstm2d_4 (ConvLSTM2D  (None, 4, 7, 7, 64)       295168    \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_average_pooling3d_1  (None, 64)                0         \n",
      "  (GlobalAveragePooling3D)                                       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2465186 (9.40 MB)\n",
      "Trainable params: 2465186 (9.40 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85aa22a1-cd1c-422b-8b4f-d367a6da0f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new, X_val_new, y_train_new,y_val_new = train_test_split(train_set, Y_train, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a98c7c41-184e-4e11-94f1-6cdc72a2c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = tf.keras.optimizers.legacy.SGD(learning_rate=0.005,  momentum=0.9, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=sgd,\n",
    "              #optimizer=ada,\n",
    "              #optimizer = Adam(lr=0.0001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77eabcf9-974c-4619-a536-7a6fb4ccc538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      " 18/138 [==>...........................] - ETA: 9:57 - loss: 0.8181 - acc: 0.9611"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Aryan/Documents/Projects/GestureSense/3DCNN_LSTM.ipynb Cell 53\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Aryan/Documents/Projects/GestureSense/3DCNN_LSTM.ipynb#Y103sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m nb_epoch \u001b[39m=\u001b[39m \u001b[39m300\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Aryan/Documents/Projects/GestureSense/3DCNN_LSTM.ipynb#Y103sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#steps_per_epoch=int((len(X_val_new)*1.5)/batch_size)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Aryan/Documents/Projects/GestureSense/3DCNN_LSTM.ipynb#Y103sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.05, \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Aryan/Documents/Projects/GestureSense/3DCNN_LSTM.ipynb#Y103sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#                                cooldown=0, patience=10, min_lr=0.005/(2^4),verbose=1)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Aryan/Documents/Projects/GestureSense/3DCNN_LSTM.ipynb#Y103sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Aryan/Documents/Projects/GestureSense/3DCNN_LSTM.ipynb#Y103sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     X_train_new,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Aryan/Documents/Projects/GestureSense/3DCNN_LSTM.ipynb#Y103sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     y_train_new,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Aryan/Documents/Projects/GestureSense/3DCNN_LSTM.ipynb#Y103sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(X_val_new,y_val_new),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Aryan/Documents/Projects/GestureSense/3DCNN_LSTM.ipynb#Y103sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Aryan/Documents/Projects/GestureSense/3DCNN_LSTM.ipynb#Y103sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     epochs \u001b[39m=\u001b[39;49m nb_epoch,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Aryan/Documents/Projects/GestureSense/3DCNN_LSTM.ipynb#Y103sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Aryan/Documents/Projects/GestureSense/3DCNN_LSTM.ipynb#Y103sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Aryan/Documents/Projects/GestureSense/3DCNN_LSTM.ipynb#Y103sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 30\n",
    "nb_epoch = 300\n",
    "#steps_per_epoch=int((len(X_val_new)*1.5)/batch_size)\n",
    "# lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.05, \n",
    "#                                cooldown=0, patience=10, min_lr=0.005/(2^4),verbose=1)\n",
    "hist = model.fit(\n",
    "    X_train_new,\n",
    "    y_train_new,\n",
    "    validation_data=(X_val_new,y_val_new),\n",
    "    batch_size=batch_size,\n",
    "    epochs = nb_epoch,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9cb6e25-3361-4ac3-9342-458b2777397c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_loss \u001b[38;5;241m=\u001b[39m \u001b[43mhist\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m hist\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(training_loss, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "training_loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "plt.plot(training_loss, label=\"training_loss\")\n",
    "plt.plot(val_loss, label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f27b8c2-82a1-4946-b82d-d7dfefba0de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']\n",
    "\n",
    "plt.plot(training_acc, label=\"training_accuracy\")\n",
    "plt.plot(val_acc, label=\"validation_accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a827eaf-372e-485e-b01d-49fef80c990c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_pred \u001b[38;5;241m=\u001b[39m\u001b[43mmodel1\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_train_new[\u001b[38;5;241m50\u001b[39m:\u001b[38;5;241m70\u001b[39m])\n\u001b[1;32m      2\u001b[0m result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(test_pred, axis \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model1' is not defined"
     ]
    }
   ],
   "source": [
    "test_pred =model.predict(X_train_new[50:70])\n",
    "result = np.argmax(test_pred, axis =1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4866473-b159-42a8-8c17-5ae7e1b629f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "met = confusion_matrix(np.argmax(y_val_new,axis =1), np.argmax(model.predict(X_val_new),axis =1))\n",
    "print(met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e4dea9-f2ac-434b-8901-0e45b2750be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def confusion_matrix_plot(cm, classes, \n",
    "                          title='Normalized Confusion Matrix', \n",
    "                          normalize=True, \n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm, decimals=2)\n",
    "        cm[np.isnan(cm)] = 0.0\n",
    "    plt.subplots(1, 1, figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e088d7ee-c785-45bb-bb97-a98b8aafa494",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_plot(met, classes = [\"Rolling Hand Backward\", \"Rolling Hand Forward\",\"No gesture\", \"Swiping Left\", \"Swiping Right\", \"Stop Sign\", \"Thumb Up\",\"Thumb Down\", \"Zooming Out With Full Hand\",\"Zooming In With Full Hand\",\"Shaking Hand\",\"Drumming Fingers\",\"Swiping Up\",\"Swiping Down\",\"Sliding Two Fingers Down\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c850c6-b7c2-4ecb-b2b6-43f2ec9cd220",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 6\n",
    "model.save(f\"./Models/{model_version}\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
