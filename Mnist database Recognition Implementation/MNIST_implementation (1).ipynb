{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Importing Important libraries\n",
        "import numpy as np # For Scientific Computation\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Cp8UoOSc--4r"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8g7qhB-Kdvn",
        "outputId": "5ed469f6-4391-4637-8419-ff91aa0841d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0OYr--39jgn",
        "outputId": "df7ce011-ea36-4012-ff0b-6476d6bff94b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "# Fetching of data\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HZZ_7gWLKIsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieving features and labels\n",
        "X = mnist['data']\n",
        "Y = mnist['target']"
      ],
      "metadata": {
        "id": "O2O4XVbA-Ksi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting into NumPy array with integer datatype\n",
        "X = np.array(X , dtype = 'int32')\n",
        "Y = np.array(Y , dtype = 'int32')"
      ],
      "metadata": {
        "id": "ZrBOddZf-dp8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping\n",
        "Y = Y.reshape(1,70000)\n",
        "X = X.reshape(70000,-1).T\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "RrLpw66v_OYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e417f280-a5f0-4f33-f46e-ce520f059751"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 70000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Lets_plot = X[:,60000]\n",
        "Lets_plot_image = Lets_plot.reshape(28,28)\n",
        "print(Lets_plot_image.shape)"
      ],
      "metadata": {
        "id": "cNzkjXXP_bs1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7f2fb70-6c04-4bcb-8110-420b058c3385"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(Lets_plot_image, cmap = matplotlib.cm.binary, interpolation = \"nearest\")"
      ],
      "metadata": {
        "id": "vztcjzEWEHl8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "95083f3f-1726-4d3e-e44f-3bec31e81ab0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7bb42e07b400>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAa00lEQVR4nO3df2zU9R3H8deB9ARtr6ulvd4orICWKVAzlK5DEUcDrRkRJYu//gBDIGJxw85puijIWFIHiyM6Bst+0JmIOjeBSRYSLbbMrWUDYYS4dbSpgqEtk427UqQw+tkfxBsH5cf3uOu7V56P5JvQu++n9/a7b/rcl7t+8TnnnAAA6GODrAcAAFydCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBxjfUA5+rp6dGhQ4eUnp4un89nPQ4AwCPnnDo7OxUKhTRo0IWvc/pdgA4dOqT8/HzrMQAAV+jgwYMaMWLEBZ/vdwFKT0+XdGbwjIwM42kAAF5FIhHl5+dHf55fSNICtGbNGq1atUrt7e0qKirSyy+/rMmTJ19y3ed/7ZaRkUGAACCFXeptlKR8COGNN95QZWWlli1bpg8++EBFRUWaOXOmDh8+nIyXAwCkoKQE6MUXX9SCBQv06KOP6uabb9a6des0bNgw/epXv0rGywEAUlDCA3Ty5Ent2rVLpaWl/3+RQYNUWlqqhoaG8/bv7u5WJBKJ2QAAA1/CA/Tpp5/q9OnTys3NjXk8NzdX7e3t5+1fXV2tQCAQ3fgEHABcHcx/EbWqqkrhcDi6HTx40HokAEAfSPin4LKzszV48GB1dHTEPN7R0aFgMHje/n6/X36/P9FjAAD6uYRfAaWlpWnSpEmqra2NPtbT06Pa2lqVlJQk+uUAACkqKb8HVFlZqblz5+q2227T5MmTtXr1anV1denRRx9NxssBAFJQUgL0wAMP6F//+peWLl2q9vZ23Xrrrdq6det5H0wAAFy9fM45Zz3E2SKRiAKBgMLhMHdCAIAUdLk/x80/BQcAuDoRIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATCQ/Q888/L5/PF7ONGzcu0S8DAEhx1yTjm95yyy169913//8i1yTlZQAAKSwpZbjmmmsUDAaT8a0BAANEUt4D2r9/v0KhkEaPHq1HHnlEBw4cuOC+3d3dikQiMRsAYOBLeICKi4tVU1OjrVu3au3atWptbdWdd96pzs7OXvevrq5WIBCIbvn5+YkeCQDQD/mccy6ZL3D06FGNGjVKL774oubPn3/e893d3eru7o5+HYlElJ+fr3A4rIyMjGSOBgBIgkgkokAgcMmf40n/dEBmZqZuuukmNTc39/q83++X3+9P9hgAgH4m6b8HdOzYMbW0tCgvLy/ZLwUASCEJD9BTTz2l+vp6ffTRR/rzn/+s++67T4MHD9ZDDz2U6JcCAKSwhP8V3CeffKKHHnpIR44c0fDhw3XHHXeosbFRw4cPT/RLAQBSWMID9Prrryf6WwIABiDuBQcAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmEj6P0iHvvXb3/7W85qf//zncb1WKBTyvObaa6/1vOaRRx7xvCYYDHpeI0ljx46Nax0A77gCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAmfc85ZD3G2SCSiQCCgcDisjIwM63FSTkFBgec1H330UeIHMRbvuXPzzTcneBIkWn5+vuc1Tz/9dFyvddttt8W17mp3uT/HuQICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExcYz0AEusXv/iF5zV/+9vf4nqteG7c+eGHH3pes3v3bs9r6urqPK+RpMbGRs9rRo4c6XnNgQMHPK/pS0OGDPG8Jjs72/OatrY2z2vi+d8onhuYStyMNNm4AgIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHAz0gFm+vTpfbImXmVlZX3yOv/5z3/iWhfPjU/juWHlX//6V89r+pLf7/e8prCw0POacePGeV7z73//2/OaMWPGeF6D5OMKCABgggABAEx4DtD27ds1a9YshUIh+Xw+bdq0KeZ555yWLl2qvLw8DR06VKWlpdq/f3+i5gUADBCeA9TV1aWioiKtWbOm1+dXrlypl156SevWrdOOHTt03XXXaebMmTpx4sQVDwsAGDg8fwihvLxc5eXlvT7nnNPq1av17LPP6t5775UkvfLKK8rNzdWmTZv04IMPXtm0AIABI6HvAbW2tqq9vV2lpaXRxwKBgIqLi9XQ0NDrmu7ubkUikZgNADDwJTRA7e3tkqTc3NyYx3Nzc6PPnau6ulqBQCC6xftvtwMAUov5p+CqqqoUDoej28GDB61HAgD0gYQGKBgMSpI6OjpiHu/o6Ig+dy6/36+MjIyYDQAw8CU0QAUFBQoGg6qtrY0+FolEtGPHDpWUlCTypQAAKc7zp+COHTum5ubm6Netra3as2ePsrKyNHLkSC1ZskQ/+MEPdOONN6qgoEDPPfecQqGQZs+enci5AQApznOAdu7cqbvvvjv6dWVlpSRp7ty5qqmp0dNPP62uri4tXLhQR48e1R133KGtW7fq2muvTdzUAICU53POOeshzhaJRBQIBBQOh3k/CEghv/vd7zyv+eY3v+l5zYQJEzyvee+99zyvkaSsrKy41l3tLvfnuPmn4AAAVycCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY8PzPMQAY+A4fPux5zeOPP+55TTw341+6dKnnNdzVun/iCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSAGcZ82aNZ7XxHMD08zMTM9rCgsLPa9B/8QVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRAgPY+++/H9e6F154IcGT9G7z5s2e14wfPz4Jk8ACV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAluRgoMYH/4wx/iWnfy5EnPa0pLSz2vKSkp8bwGAwdXQAAAEwQIAGDCc4C2b9+uWbNmKRQKyefzadOmTTHPz5s3Tz6fL2YrKytL1LwAgAHCc4C6urpUVFSkNWvWXHCfsrIytbW1RbfXXnvtioYEAAw8nj+EUF5ervLy8ovu4/f7FQwG4x4KADDwJeU9oLq6OuXk5KiwsFCLFi3SkSNHLrhvd3e3IpFIzAYAGPgSHqCysjK98sorqq2t1Q9/+EPV19ervLxcp0+f7nX/6upqBQKB6Jafn5/okQAA/VDCfw/owQcfjP55woQJmjhxosaMGaO6ujpNnz79vP2rqqpUWVkZ/ToSiRAhALgKJP1j2KNHj1Z2draam5t7fd7v9ysjIyNmAwAMfEkP0CeffKIjR44oLy8v2S8FAEghnv8K7tixYzFXM62trdqzZ4+ysrKUlZWl5cuXa86cOQoGg2ppadHTTz+tsWPHaubMmQkdHACQ2jwHaOfOnbr77rujX3/+/s3cuXO1du1a7d27V7/+9a919OhRhUIhzZgxQytWrJDf70/c1ACAlOdzzjnrIc4WiUQUCAQUDod5Pwg4y2effeZ5zZQpU+J6rQ8//NDzmm3btnle87Wvfc3zGvR/l/tznHvBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwETC/0luAMmxatUqz2t2794d12uVl5d7XsOdreEVV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAluRgoY2LJli+c1K1as8LwmEAh4XiNJzz33XFzrAC+4AgIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHAzUuAKHTlyxPOab33rW57X/Pe///W85p577vG8RpJKSkriWgd4wRUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCm5ECZzl9+rTnNWVlZZ7XtLa2el4zduxYz2tWrFjheQ3QV7gCAgCYIEAAABOeAlRdXa3bb79d6enpysnJ0ezZs9XU1BSzz4kTJ1RRUaEbbrhB119/vebMmaOOjo6EDg0ASH2eAlRfX6+Kigo1NjbqnXfe0alTpzRjxgx1dXVF93nyySf19ttv680331R9fb0OHTqk+++/P+GDAwBSm6cPIWzdujXm65qaGuXk5GjXrl2aOnWqwuGwfvnLX2rDhg36+te/Lklav369vvzlL6uxsVFf/epXEzc5ACClXdF7QOFwWJKUlZUlSdq1a5dOnTql0tLS6D7jxo3TyJEj1dDQ0Ov36O7uViQSidkAAANf3AHq6enRkiVLNGXKFI0fP16S1N7errS0NGVmZsbsm5ubq/b29l6/T3V1tQKBQHTLz8+PdyQAQAqJO0AVFRXat2+fXn/99SsaoKqqSuFwOLodPHjwir4fACA1xPWLqIsXL9aWLVu0fft2jRgxIvp4MBjUyZMndfTo0ZiroI6ODgWDwV6/l9/vl9/vj2cMAEAK83QF5JzT4sWLtXHjRm3btk0FBQUxz0+aNElDhgxRbW1t9LGmpiYdOHBAJSUliZkYADAgeLoCqqio0IYNG7R582alp6dH39cJBAIaOnSoAoGA5s+fr8rKSmVlZSkjI0NPPPGESkpK+AQcACCGpwCtXbtWkjRt2rSYx9evX6958+ZJkn784x9r0KBBmjNnjrq7uzVz5kz99Kc/TciwAICBw+ecc9ZDnC0SiSgQCCgcDisjI8N6HFxl/vnPf3peU1hYmIRJzvf73//e85pZs2YlYRLg4i735zj3ggMAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJuP5FVKC/+/jjj+NaN2PGjARP0rsf/ehHntd84xvfSMIkgB2ugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFAPSz372s7jWxXsTU6/uuusuz2t8Pl8SJgHscAUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqTo9/74xz96XvOTn/wkCZMASCSugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFP3e+++/73lNZ2dnEibp3dixYz2vuf7665MwCZBauAICAJggQAAAE54CVF1drdtvv13p6enKycnR7Nmz1dTUFLPPtGnT5PP5YrbHHnssoUMDAFKfpwDV19eroqJCjY2Neuedd3Tq1CnNmDFDXV1dMfstWLBAbW1t0W3lypUJHRoAkPo8fQhh69atMV/X1NQoJydHu3bt0tSpU6OPDxs2TMFgMDETAgAGpCt6DygcDkuSsrKyYh5/9dVXlZ2drfHjx6uqqkrHjx+/4Pfo7u5WJBKJ2QAAA1/cH8Pu6enRkiVLNGXKFI0fPz76+MMPP6xRo0YpFApp7969euaZZ9TU1KS33nqr1+9TXV2t5cuXxzsGACBFxR2giooK7du377zf0Vi4cGH0zxMmTFBeXp6mT5+ulpYWjRkz5rzvU1VVpcrKyujXkUhE+fn58Y4FAEgRcQVo8eLF2rJli7Zv364RI0ZcdN/i4mJJUnNzc68B8vv98vv98YwBAEhhngLknNMTTzyhjRs3qq6uTgUFBZdcs2fPHklSXl5eXAMCAAYmTwGqqKjQhg0btHnzZqWnp6u9vV2SFAgENHToULW0tGjDhg265557dMMNN2jv3r168sknNXXqVE2cODEp/wEAgNTkKUBr166VdOaXTc+2fv16zZs3T2lpaXr33Xe1evVqdXV1KT8/X3PmzNGzzz6bsIEBAAOD57+Cu5j8/HzV19df0UAAgKsDd8MGznLrrbd6XlNbW+t5zbm/OwdcjbgZKQDABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgwucudYvrPhaJRBQIBBQOh5WRkWE9DgDAo8v9Oc4VEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPXWA9wrs9vTReJRIwnAQDE4/Of35e61Wi/C1BnZ6ckKT8/33gSAMCV6OzsVCAQuODz/e5u2D09PTp06JDS09Pl8/linotEIsrPz9fBgwev6jtlcxzO4DicwXE4g+NwRn84Ds45dXZ2KhQKadCgC7/T0++ugAYNGqQRI0ZcdJ+MjIyr+gT7HMfhDI7DGRyHMzgOZ1gfh4td+XyODyEAAEwQIACAiZQKkN/v17Jly+T3+61HMcVxOIPjcAbH4QyOwxmpdBz63YcQAABXh5S6AgIADBwECABgggABAEwQIACAiZQJ0Jo1a/SlL31J1157rYqLi/WXv/zFeqQ+9/zzz8vn88Vs48aNsx4r6bZv365Zs2YpFArJ5/Np06ZNMc8757R06VLl5eVp6NChKi0t1f79+22GTaJLHYd58+add36UlZXZDJsk1dXVuv3225Wenq6cnBzNnj1bTU1NMfucOHFCFRUVuuGGG3T99ddrzpw56ujoMJo4OS7nOEybNu288+Gxxx4zmrh3KRGgN954Q5WVlVq2bJk++OADFRUVaebMmTp8+LD1aH3ulltuUVtbW3R7//33rUdKuq6uLhUVFWnNmjW9Pr9y5Uq99NJLWrdunXbs2KHrrrtOM2fO1IkTJ/p40uS61HGQpLKyspjz47XXXuvDCZOvvr5eFRUVamxs1DvvvKNTp05pxowZ6urqiu7z5JNP6u2339abb76p+vp6HTp0SPfff7/h1Il3OcdBkhYsWBBzPqxcudJo4gtwKWDy5MmuoqIi+vXp06ddKBRy1dXVhlP1vWXLlrmioiLrMUxJchs3box+3dPT44LBoFu1alX0saNHjzq/3+9ee+01gwn7xrnHwTnn5s6d6+69916TeawcPnzYSXL19fXOuTP/2w8ZMsS9+eab0X3+/ve/O0muoaHBasykO/c4OOfcXXfd5b797W/bDXUZ+v0V0MmTJ7Vr1y6VlpZGHxs0aJBKS0vV0NBgOJmN/fv3KxQKafTo0XrkkUd04MAB65FMtba2qr29Peb8CAQCKi4uvirPj7q6OuXk5KiwsFCLFi3SkSNHrEdKqnA4LEnKysqSJO3atUunTp2KOR/GjRunkSNHDujz4dzj8LlXX31V2dnZGj9+vKqqqnT8+HGL8S6o392M9FyffvqpTp8+rdzc3JjHc3Nz9Y9//MNoKhvFxcWqqalRYWGh2tratHz5ct15553at2+f0tPTrccz0d7eLkm9nh+fP3e1KCsr0/3336+CggK1tLToe9/7nsrLy9XQ0KDBgwdbj5dwPT09WrJkiaZMmaLx48dLOnM+pKWlKTMzM2bfgXw+9HYcJOnhhx/WqFGjFAqFtHfvXj3zzDNqamrSW2+9ZThtrH4fIPxfeXl59M8TJ05UcXGxRo0apd/85jeaP3++4WToDx588MHonydMmKCJEydqzJgxqqur0/Tp0w0nS46Kigrt27fvqngf9GIudBwWLlwY/fOECROUl5en6dOnq6WlRWPGjOnrMXvV7/8KLjs7W4MHDz7vUywdHR0KBoNGU/UPmZmZuummm9Tc3Gw9ipnPzwHOj/ONHj1a2dnZA/L8WLx4sbZs2aL33nsv5p9vCQaDOnnypI4ePRqz/0A9Hy50HHpTXFwsSf3qfOj3AUpLS9OkSZNUW1sbfaynp0e1tbUqKSkxnMzesWPH1NLSory8POtRzBQUFCgYDMacH5FIRDt27Ljqz49PPvlER44cGVDnh3NOixcv1saNG7Vt2zYVFBTEPD9p0iQNGTIk5nxoamrSgQMHBtT5cKnj0Js9e/ZIUv86H6w/BXE5Xn/9def3+11NTY378MMP3cKFC11mZqZrb2+3Hq1Pfec733F1dXWutbXV/elPf3KlpaUuOzvbHT582Hq0pOrs7HS7d+92u3fvdpLciy++6Hbv3u0+/vhj55xzL7zwgsvMzHSbN292e/fudffee68rKChwn332mfHkiXWx49DZ2emeeuop19DQ4FpbW927777rvvKVr7gbb7zRnThxwnr0hFm0aJELBAKurq7OtbW1Rbfjx49H93nsscfcyJEj3bZt29zOnTtdSUmJKykpMZw68S51HJqbm933v/99t3PnTtfa2uo2b97sRo8e7aZOnWo8eayUCJBzzr388stu5MiRLi0tzU2ePNk1NjZaj9TnHnjgAZeXl+fS0tLcF7/4RffAAw+45uZm67GS7r333nOSztvmzp3rnDvzUeznnnvO5ebmOr/f76ZPn+6amppsh06Cix2H48ePuxkzZrjhw4e7IUOGuFGjRrkFCxYMuP+T1tt/vyS3fv366D6fffaZe/zxx90XvvAFN2zYMHffffe5trY2u6GT4FLH4cCBA27q1KkuKyvL+f1+N3bsWPfd737XhcNh28HPwT/HAAAw0e/fAwIADEwECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgIn/AXUYjuKM3UN2AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y[:,60000]"
      ],
      "metadata": {
        "id": "zlheGs0_Hygg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e4d23c8-2fe6-4b11-8ef7-f6441d7e2d24"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X[:,:60000]\n",
        "X_test  = X[:,60000:]\n",
        "Y_train = Y[:,:60000]\n",
        "Y_test  = Y[:,60000:]\n",
        "X_train = X_train\n",
        "X_test = X_test\n",
        "print(X_train.shape)\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "metadata": {
        "id": "5V_01X5BP180",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59488858-8575-4cc5-c989-199ccad351c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 60000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters():\n",
        "  W1 = np.random.randn(16,784) * 0.01\n",
        "  W2 = np.random.randn(10,16)  * 0.01\n",
        "  b1 = np.zeros((16,1))\n",
        "  b2 = np.zeros((10,1))\n",
        "  # parameters = {\n",
        "  #     \"W1\": W1,\n",
        "  #     \"b1\": b1,\n",
        "  #     \"W2\": W2,\n",
        "  #     \"b2\": b2}\n",
        "  return W1, b1, W2, b2\n"
      ],
      "metadata": {
        "id": "kVt7VGS8A3-P"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ReLU(Z):\n",
        "  return np.maximum(Z, 0)\n",
        "\n",
        "def SoftMax(Z2):\n",
        "  A = np.exp(Z2) / np.sum(np.exp(Z2), axis = 0, keepdims = True)\n",
        "  return A\n",
        "\n",
        "def forward_propagation(W1, b1, W2, b2,X):\n",
        "  Z1 = np.dot(W1,X) + b1\n",
        "  A1 = ReLU(Z1)\n",
        "  Z2 = np.dot(W2,A1) + b2\n",
        "  Z2 = np.float128(Z2)\n",
        "  A2 = SoftMax(Z2)\n",
        "  return Z1, A1, Z2, A2\n"
      ],
      "metadata": {
        "id": "J--6Cm8NA363"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_cost(A2, Y):\n",
        "  m = Y.size\n",
        "  cost = -1/m * np.sum(np.dot(Y,np.log(A2).T) + np.dot((1-Y),np.log(1-A2).T))\n",
        "  return cost"
      ],
      "metadata": {
        "id": "xLEX4RIKA34B"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(Y):\n",
        "  encoded_array = np.zeros((Y.size, Y.max() + 1))\n",
        "  encoded_array[np.arange(Y.size), Y] = 1\n",
        "  encoded_array = encoded_array.T\n",
        "  return encoded_array\n",
        "\n",
        "def relu_derivative(Z):\n",
        "  return Z >= 0\n",
        "\n",
        "def backward_propagation(Z1, A1, Z2, A2, W2, X, Y):\n",
        "  m = Y.size\n",
        "  one_hot_Y = one_hot(Y)\n",
        "  dZ2 = A2 - one_hot_Y\n",
        "  dW2 = 1/m * np.dot(dZ2,A1.T)\n",
        "  db2 = 1/m * np.sum(dZ2, axis = 1, keepdims = True)\n",
        "  dZ1 = np.dot(W2.T, dZ2) * relu_derivative(Z1)\n",
        "  dW1 = 1/m * np.dot(dZ1,X.T)\n",
        "  db1 = 1/m * np.sum(dZ1,axis = 1, keepdims = True)\n",
        "  return dW1, db1, dW2, db2\n"
      ],
      "metadata": {
        "id": "RE7tZU_NA307"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, Learning_rate):\n",
        "  # W1 = parameters[\"W1\"]\n",
        "  # W2 = parameters[\"W2\"]\n",
        "  # b1 = parameters[\"b1\"]\n",
        "  # b2 = parameters[\"b2\"]\n",
        "  W1 = W1 - Learning_rate * dW1\n",
        "  W2 = W2 - Learning_rate * dW2\n",
        "  b1 = b1 - Learning_rate * db1\n",
        "  b2 = b2 - Learning_rate * db2\n",
        "  # parameters[\"W1\"] = W1\n",
        "  # parameters[\"W2\"] = W2\n",
        "  # parameters[\"b1\"] = b1\n",
        "  # parameters[\"b2\"] = b2\n",
        "  return W1, b1, W2, b2"
      ],
      "metadata": {
        "id": "wjzkxcb3aZKb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(A2):\n",
        "  return np.argmax(A2, 0)\n",
        "\n",
        "def get_accuracy(predictions, Y):\n",
        "  print(predictions, Y)\n",
        "  return np.sum(predictions == Y)/ Y.size\n",
        "\n",
        "def Gradient_Descent(X, Y, No_Of_Iterations, Learning_Rate):\n",
        "  W1, b1, W2, b2 = initialize_parameters()\n",
        "\n",
        "  for i in range(0, No_Of_Iterations):\n",
        "    Z1, A1, Z2, A2 = forward_propagation(W1, b1, W2, b2, X)\n",
        "    cost = compute_cost(A2, Y)\n",
        "    dW1, db1, dW2, db2 = backward_propagation(Z1, A1, Z2, A2, W2, X, Y)\n",
        "    W1, b1, W2, b2 = update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, Learning_Rate)\n",
        "    if i% 10 == 0:\n",
        "      print(\"Cost after \" + str(i) + \"th Iteration is \" + str(cost))\n",
        "    if i % 10 == 0 or i == No_Of_Iterations:\n",
        "      print(\"Iterations: \" + str(i))\n",
        "      predictions = get_predictions(A2)\n",
        "      print(\"Accuracy  :\" + str(get_accuracy(predictions, Y)))\n",
        "\n",
        "  return W1, b1, W2, b2, cost"
      ],
      "metadata": {
        "id": "KIeEE8r15usA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W1, b1, W2, b2, cost = Gradient_Descent(X_train, Y_train, 500, 0.1)"
      ],
      "metadata": {
        "id": "urqjifhxPObj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b302b542-9f91-4b41-c623-c202a071825d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after 0th Iteration is 98.916686037468436014\n",
            "Iterations: 0\n",
            "[3 2 3 ... 3 3 3] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.05675\n",
            "Cost after 10th Iteration is 98.91735394380567808\n",
            "Iterations: 10\n",
            "[3 1 1 ... 1 1 1] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.14061666666666667\n",
            "Cost after 20th Iteration is 98.918808133407523576\n",
            "Iterations: 20\n",
            "[6 1 1 ... 1 1 1] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.17776666666666666\n",
            "Cost after 30th Iteration is 98.92137541644367953\n",
            "Iterations: 30\n",
            "[6 1 1 ... 1 6 1] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.2669166666666667\n",
            "Cost after 40th Iteration is 98.928713673852889575\n",
            "Iterations: 40\n",
            "[6 6 3 ... 9 6 1] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.3137333333333333\n",
            "Cost after 50th Iteration is 98.96007650456410244\n",
            "Iterations: 50\n",
            "[6 6 6 ... 9 6 6] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.2997166666666667\n",
            "Cost after 60th Iteration is 99.097977396772943655\n",
            "Iterations: 60\n",
            "[6 6 6 ... 9 6 6] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.2769333333333333\n",
            "Cost after 70th Iteration is 99.604841838854195034\n",
            "Iterations: 70\n",
            "[6 0 4 ... 9 6 6] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.3202\n",
            "Cost after 80th Iteration is 101.065733473687032966\n",
            "Iterations: 80\n",
            "[0 0 4 ... 9 0 6] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.39265\n",
            "Cost after 90th Iteration is 104.16007124692399082\n",
            "Iterations: 90\n",
            "[0 0 4 ... 9 0 0] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.5045833333333334\n",
            "Cost after 100th Iteration is 108.86737136717742004\n",
            "Iterations: 100\n",
            "[0 0 4 ... 9 0 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.6140333333333333\n",
            "Cost after 110th Iteration is 115.42318718398995064\n",
            "Iterations: 110\n",
            "[3 0 4 ... 9 0 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.6602166666666667\n",
            "Cost after 120th Iteration is 124.554652627876884345\n",
            "Iterations: 120\n",
            "[3 0 4 ... 8 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.6908666666666666\n",
            "Cost after 130th Iteration is 135.62731494512984648\n",
            "Iterations: 130\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.7198833333333333\n",
            "Cost after 140th Iteration is 147.30120137917124777\n",
            "Iterations: 140\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.7440166666666667\n",
            "Cost after 150th Iteration is 158.7102235422076131\n",
            "Iterations: 150\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.7636833333333334\n",
            "Cost after 160th Iteration is 169.48664810660436741\n",
            "Iterations: 160\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.7806166666666666\n",
            "Cost after 170th Iteration is 179.51083178807581155\n",
            "Iterations: 170\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.7942333333333333\n",
            "Cost after 180th Iteration is 188.77521093773809885\n",
            "Iterations: 180\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8057333333333333\n",
            "Cost after 190th Iteration is 197.32535173652229651\n",
            "Iterations: 190\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8155\n",
            "Cost after 200th Iteration is 205.21550316836495335\n",
            "Iterations: 200\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8235\n",
            "Cost after 210th Iteration is 212.50958289555644178\n",
            "Iterations: 210\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8306833333333333\n",
            "Cost after 220th Iteration is 219.26379044850272146\n",
            "Iterations: 220\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8371\n",
            "Cost after 230th Iteration is 225.5311621286876619\n",
            "Iterations: 230\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8432333333333333\n",
            "Cost after 240th Iteration is 231.36344727971777917\n",
            "Iterations: 240\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8482666666666666\n",
            "Cost after 250th Iteration is 236.80034273881387559\n",
            "Iterations: 250\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.853\n",
            "Cost after 260th Iteration is 241.88324329566712287\n",
            "Iterations: 260\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8573166666666666\n",
            "Cost after 270th Iteration is 246.64119815871517931\n",
            "Iterations: 270\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.86125\n",
            "Cost after 280th Iteration is 251.10574013615116516\n",
            "Iterations: 280\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.86475\n",
            "Cost after 290th Iteration is 255.30100480621147846\n",
            "Iterations: 290\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8679\n",
            "Cost after 300th Iteration is 259.2473179416992369\n",
            "Iterations: 300\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8703333333333333\n",
            "Cost after 310th Iteration is 262.9677464322372528\n",
            "Iterations: 310\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8721833333333333\n",
            "Cost after 320th Iteration is 266.47803725140315811\n",
            "Iterations: 320\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8742166666666666\n",
            "Cost after 330th Iteration is 269.7955718224226695\n",
            "Iterations: 330\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.87605\n",
            "Cost after 340th Iteration is 272.93439578060347925\n",
            "Iterations: 340\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.87795\n",
            "Cost after 350th Iteration is 275.90332154271814435\n",
            "Iterations: 350\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8799833333333333\n",
            "Cost after 360th Iteration is 278.71861379263327935\n",
            "Iterations: 360\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8811833333333333\n",
            "Cost after 370th Iteration is 281.38829409996966505\n",
            "Iterations: 370\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8824666666666666\n",
            "Cost after 380th Iteration is 283.92263216547110755\n",
            "Iterations: 380\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8839833333333333\n",
            "Cost after 390th Iteration is 286.33045291483165862\n",
            "Iterations: 390\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8854833333333333\n",
            "Cost after 400th Iteration is 288.6204892793068061\n",
            "Iterations: 400\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8867166666666667\n",
            "Cost after 410th Iteration is 290.80016234654897175\n",
            "Iterations: 410\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.88765\n",
            "Cost after 420th Iteration is 292.87740084120323825\n",
            "Iterations: 420\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.88855\n",
            "Cost after 430th Iteration is 294.85731212461898393\n",
            "Iterations: 430\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8893666666666666\n",
            "Cost after 440th Iteration is 296.7456170569911211\n",
            "Iterations: 440\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8902166666666667\n",
            "Cost after 450th Iteration is 298.5478551569056276\n",
            "Iterations: 450\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8910166666666667\n",
            "Cost after 460th Iteration is 300.2703317852213593\n",
            "Iterations: 460\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8919166666666667\n",
            "Cost after 470th Iteration is 301.91770661161656372\n",
            "Iterations: 470\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8927166666666667\n",
            "Cost after 480th Iteration is 303.4961476209474699\n",
            "Iterations: 480\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8933666666666666\n",
            "Cost after 490th Iteration is 305.00671854950274606\n",
            "Iterations: 490\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.89425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z1, A1, Z2, A2 = forward_propagation(W1, b1, W2, b2, X_test)\n",
        "predictions = get_predictions(A2)\n",
        "print(\"Accuracy  :\" + str(get_accuracy(predictions, Y_test)))"
      ],
      "metadata": {
        "id": "DlCBK6YUpU3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f98f4d31-e1ae-47b4-82ad-4a38fd6e11e2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 2 1 ... 4 5 6] [[7 2 1 ... 4 5 6]]\n",
            "Accuracy  :0.8964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C3yHzltH_UyK"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}