{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gwwv4g0keJEJ"
      },
      "outputs": [],
      "source": [
        "# Importing Important libraries\n",
        "import jax\n",
        "import numpy as np              # For Scientific Computation\n",
        "import matplotlib.pyplot as plt # Visualization Library\n",
        "import jax.numpy as jnp         # For importing jax]\n",
        "from jax import grad, vmap, jit # For importing Transformation functions\n",
        "from jax import random\n",
        "import matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetching of data\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tqEvRFeetgy",
        "outputId": "b3b34024-29ff-48d6-d3fc-b08c17750b40"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieving features and labels\n",
        "X = mnist['data']\n",
        "Y = mnist['target']"
      ],
      "metadata": {
        "id": "q0xH5F1Ievhq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting into NumPy array with integer datatype\n",
        "X = jnp.array(X , dtype = 'int32')\n",
        "Y = jnp.array(Y , dtype = 'int32')"
      ],
      "metadata": {
        "id": "nTUnxGFFexbg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #loading data on gpu\n",
        "if jax.devices(\"gpu\"):\n",
        "    gpu_device = jax.devices(\"gpu\")[0]\n",
        "    X = jax.device_put(X, device = gpu_device)\n",
        "    Y = jax.device_put(Y, device = gpu_device)\n",
        "else:\n",
        "    print(\"No GPU devices found.\")"
      ],
      "metadata": {
        "id": "k98tlFhvDupX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping\n",
        "Y = Y.reshape(1,70000)\n",
        "X = X.reshape(70000,-1).T\n",
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I9CqujKezEK",
        "outputId": "ba1fd5e9-6c1b-4837-de34-f5866e0d47e2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 70000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifying the shape of image\n",
        "Lets_plot = X[:,60000]\n",
        "Lets_plot_image = Lets_plot.reshape(28,28)\n",
        "print(Lets_plot_image.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi_wPx98ezZt",
        "outputId": "6616ed55-3cc0-4a6c-b045-f199f6ccb304"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting any one image to verify the correct fetching of data\n",
        "plt.imshow(Lets_plot_image, cmap = matplotlib.cm.binary, interpolation = \"nearest\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "mlvCKUxBe2Zy",
        "outputId": "c4e094b9-41fd-4671-d36f-ab2bf1861011"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x79b3daa10550>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Corresponding to above image\n",
        "Y[:,60000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRy6zyfDe3_h",
        "outputId": "f1f3b591-9ade-41ed-94f2-b9685e0b47e0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([7], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-Processing of the data\n",
        "X_train = X[:,:60000]\n",
        "X_test  = X[:,60000:]\n",
        "Y_train = Y[:,:60000]\n",
        "Y_test  = Y[:,60000:]\n",
        "X_train = X_train\n",
        "X_test = X_test\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "Y_train.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiW7qa_8e51J",
        "outputId": "8d967684-6153-40b7-c067-fc87cb7067fe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization\n",
        "def initialize_parameters():\n",
        "  seed = 0\n",
        "  key = random.PRNGKey(seed)\n",
        "  W1 = random.normal(key,(196,784)) * 0.01\n",
        "  W2 = random.normal(key,(98,196))  * 0.01\n",
        "  W3 = random.normal(key,(49,98))   * 0.01\n",
        "  W4 = random.normal(key,(10,49))   * 0.01\n",
        "  b1 = jnp.zeros((196,1))\n",
        "  b2 = jnp.zeros((98,1))\n",
        "  b3 = jnp.zeros((49,1))\n",
        "  b4 = jnp.zeros((10,1))\n",
        "  parameters = { \"W1\": W1, \"W2\": W2, \"W3\": W3, \"W4\": W4, \"b1\": b1, \"b2\": b2, \"b3\": b3, \"b4\": b4 }\n",
        "  return parameters\n",
        "  # Activations\n",
        "def ReLU(Z):\n",
        "  return jnp.maximum(Z, 0)\n",
        "\n",
        "def SoftMax(Z):\n",
        "  A = jnp.exp(Z) / jnp.sum(jnp.exp(Z), axis = 0, keepdims = True)\n",
        "  return A"
      ],
      "metadata": {
        "id": "Ya2IOetRe7w6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward Propagation\n",
        "def forward_propagation(params, X):\n",
        "  W1 = params[\"W1\"]\n",
        "  W2 = params[\"W2\"]\n",
        "  W3 = params[\"W3\"]\n",
        "  W4 = params[\"W4\"]\n",
        "  b1 = params[\"b1\"]\n",
        "  b2 = params[\"b2\"]\n",
        "  b3 = params[\"b3\"]\n",
        "  b4 = params[\"b4\"]\n",
        "  Z1 = jnp.dot(W1,X) + b1\n",
        "  A1 = ReLU(Z1)\n",
        "  Z2 = jnp.dot(W2,A1) + b2\n",
        "  A2 = ReLU(Z2)\n",
        "  Z3 = jnp.dot(W3,A2) + b3\n",
        "  A3 = ReLU(Z3)\n",
        "  Z4 = jnp.dot(W4,A3) + b4\n",
        "  A4 = SoftMax(Z4)\n",
        "  return Z1, A1, Z2, A2, Z3, A3, Z4, A4"
      ],
      "metadata": {
        "id": "Jo-IEjvGe_Xn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(A4, Y):\n",
        "  m = Y.size\n",
        "  cost = -1/m * jnp.sum(Y*jnp.log(A4))\n",
        "  return cost"
      ],
      "metadata": {
        "id": "6MYJN-p4fDRe"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(Y):\n",
        "  encoded_array = jnp.zeros((Y.size, Y.max() + 1), dtype = \"int32\")\n",
        "  # Jax object does not support item assignment. JAX arrays are immutable. Therefore, we use set method\n",
        "  encoded_array = encoded_array.at[jnp.arange(Y.size), Y].set(1)\n",
        "  encoded_array = jnp.transpose(encoded_array)\n",
        "  return encoded_array\n",
        "\n",
        "def relu_derivative(Z):\n",
        "  return Z >= 0"
      ],
      "metadata": {
        "id": "kNoXzJIgfHOO"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# backward Propagation\n",
        "def backward_propagation(Z1, A1, Z2, A2, Z3, A3, Z4, A4, W2, W3, W4, X, Y):\n",
        "  m = Y.size\n",
        "  dZ4 = A4 - one_hot(Y)\n",
        "  dW4 = 1/m * jnp.dot(dZ4, jnp.transpose(A3))\n",
        "  db4 = 1/m * jnp.sum(dZ4, axis =1, keepdims = True)\n",
        "  dZ3 = np.dot(jnp.transpose(W4), dZ4) * relu_derivative(Z3)\n",
        "  dW3 = 1/m * jnp.dot(dZ3, jnp.transpose(A2))\n",
        "  db3 = 1/m * jnp.sum(dZ3, axis =1, keepdims = True)\n",
        "  dZ2 = jnp.dot(jnp.transpose(W3), dZ3) * relu_derivative(Z2)\n",
        "  dW2 = 1/m * jnp.dot(dZ2, jnp.transpose(A1))\n",
        "  db2 = 1/m * jnp.sum(dZ2, axis = 1, keepdims = True)\n",
        "  dZ1 = jnp.dot(jnp.transpose(W2), dZ2) * relu_derivative(Z1)\n",
        "  dW1 = 1/m * jnp.dot(dZ1, jnp.transpose(X))\n",
        "  db1 = 1/m * jnp.sum(dZ1,axis = 1, keepdims = True)\n",
        "  grads ={ \"dW1\": dW1, \"dW2\": dW2, \"dW3\": dW3, \"dW4\": dW4, \"db1\": db1, \"db2\": db2, \"db3\": db3, \"db4\": db4  }\n",
        "  return grads"
      ],
      "metadata": {
        "id": "GWNicHKrfIgx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(params,grads, Learning_rate):\n",
        "  parameters = params.copy()\n",
        "\n",
        "  L = len(parameters)//2\n",
        "\n",
        "  for l in range(L):\n",
        "      parameters[\"W\" + str(l+1)] = params[\"W\" + str(l+1)] - Learning_rate*grads[\"dW\" + str(l+1)]\n",
        "      parameters[\"b\" + str(l+1)] = params[\"b\" + str(l+1)] - Learning_rate*grads[\"db\" + str(l+1)]\n",
        "\n",
        "  return parameters"
      ],
      "metadata": {
        "id": "ZYX2M9ElfJ49"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(A2):\n",
        "  return jnp.argmax(A2, 0)\n",
        "\n",
        "def get_accuracy(predictions, Y):\n",
        "  print(predictions, Y)\n",
        "  return jnp.sum(predictions == Y)/ Y.size\n",
        "\n",
        "def Gradient_Descent(X, Y, No_Of_Iterations, Learning_Rate):\n",
        "  parameters = initialize_parameters()\n",
        "\n",
        "  for i in range(0, No_Of_Iterations):\n",
        "    Z1, A1, Z2, A2, Z3, A3, Z4, A4 = forward_propagation(parameters, X)\n",
        "    cost = compute_cost(A4, one_hot(Y))\n",
        "    grads = backward_propagation(Z1, A1, Z2, A2, Z3, A3, Z4, A4, parameters[\"W2\"], parameters[\"W3\"], parameters[\"W4\"], X, Y)\n",
        "    parameters = update_parameters(parameters, grads, Learning_Rate)\n",
        "    if i% 100 == 0:\n",
        "      print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
        "    if i % 100 == 0 or i == No_Of_Iterations:\n",
        "      print(\"Iterations: \" + str(i))\n",
        "      predictions = get_predictions(A4)\n",
        "      print(\"Accuracy  :\" + str(get_accuracy(predictions, Y)))\n",
        "  return parameters, cost"
      ],
      "metadata": {
        "id": "hPKyzRTkfMyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters, cost = Gradient_Descent(X_train, Y_train, 5000, 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAltfuFdfNa7",
        "outputId": "8d7426ce-bd49-445a-dd77-8b13f00dca8a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 0: 0.2302585393190384\n",
            "Iterations: 0\n",
            "[4 2 2 ... 5 2 5] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.081133336\n",
            "Cost after iteration 100: 0.23011666536331177\n",
            "Iterations: 100\n",
            "[1 1 1 ... 1 1 1] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.11236667\n",
            "Cost after iteration 200: 0.23011338710784912\n",
            "Iterations: 200\n",
            "[1 1 1 ... 1 1 1] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.11236667\n",
            "Cost after iteration 300: 0.2301119714975357\n",
            "Iterations: 300\n",
            "[1 1 1 ... 1 1 1] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.11236667\n",
            "Cost after iteration 400: 0.23011015355587006\n",
            "Iterations: 400\n",
            "[1 1 1 ... 1 1 1] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.11236667\n",
            "Cost after iteration 500: 0.23010729253292084\n",
            "Iterations: 500\n",
            "[1 1 1 ... 1 1 1] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.11236667\n",
            "Cost after iteration 600: 0.23010241985321045\n",
            "Iterations: 600\n",
            "[1 1 1 ... 1 1 1] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.11236667\n",
            "Cost after iteration 700: 0.23009374737739563\n",
            "Iterations: 700\n",
            "[1 1 1 ... 1 1 1] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.11236667\n",
            "Cost after iteration 800: 0.2300748974084854\n",
            "Iterations: 800\n",
            "[1 1 1 ... 1 1 1] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.11236667\n",
            "Cost after iteration 900: 0.23001708090305328\n",
            "Iterations: 900\n",
            "[1 1 1 ... 1 1 1] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.11236667\n",
            "Cost after iteration 1000: 0.22959598898887634\n",
            "Iterations: 1000\n",
            "[1 1 1 ... 1 1 1] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.11236667\n",
            "Cost after iteration 1100: 0.18762190639972687\n",
            "Iterations: 1100\n",
            "[0 0 1 ... 1 0 3] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.24811667\n",
            "Cost after iteration 1200: 0.14469851553440094\n",
            "Iterations: 1200\n",
            "[3 6 7 ... 8 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.39473334\n",
            "Cost after iteration 1300: 0.09525622427463531\n",
            "Iterations: 1300\n",
            "[3 0 9 ... 8 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.645\n",
            "Cost after iteration 1400: 0.04687285050749779\n",
            "Iterations: 1400\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8686\n",
            "Cost after iteration 1500: 0.03270309045910835\n",
            "Iterations: 1500\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.9103167\n",
            "Cost after iteration 1600: 0.12153877317905426\n",
            "Iterations: 1600\n",
            "[5 5 4 ... 5 4 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.60678333\n",
            "Cost after iteration 1700: 0.020835580304265022\n",
            "Iterations: 1700\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.9436\n",
            "Cost after iteration 1800: 0.020553531125187874\n",
            "Iterations: 1800\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.94498336\n",
            "Cost after iteration 1900: 0.016396326944231987\n",
            "Iterations: 1900\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.9558167\n",
            "Cost after iteration 2000: 0.014917119406163692\n",
            "Iterations: 2000\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.95945\n",
            "Cost after iteration 2100: 0.013689659535884857\n",
            "Iterations: 2100\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.9633833\n",
            "Cost after iteration 2200: 0.011902522295713425\n",
            "Iterations: 2200\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.96818334\n",
            "Cost after iteration 2300: 0.012100151740014553\n",
            "Iterations: 2300\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.9665834\n",
            "Cost after iteration 2400: 1.8585070371627808\n",
            "Iterations: 2400\n",
            "[6 6 6 ... 6 6 6] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.098633334\n",
            "Cost after iteration 2500: 0.06143792346119881\n",
            "Iterations: 2500\n",
            "[5 0 4 ... 5 0 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.8071167\n",
            "Cost after iteration 2600: 0.01952666975557804\n",
            "Iterations: 2600\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.9453167\n",
            "Cost after iteration 2700: 0.014868291094899178\n",
            "Iterations: 2700\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.9572833\n",
            "Cost after iteration 2800: 0.012014126405119896\n",
            "Iterations: 2800\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.96595\n",
            "Cost after iteration 2900: 0.01016909722238779\n",
            "Iterations: 2900\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.9716833\n",
            "Cost after iteration 3000: 0.008923530578613281\n",
            "Iterations: 3000\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.97511667\n",
            "Cost after iteration 3100: 0.007872231304645538\n",
            "Iterations: 3100\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.9781167\n",
            "Cost after iteration 3200: 0.018723782151937485\n",
            "Iterations: 3200\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.9472167\n",
            "Cost after iteration 3300: 0.011686334386467934\n",
            "Iterations: 3300\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.96456665\n",
            "Cost after iteration 3400: 0.010852129198610783\n",
            "Iterations: 3400\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.96750003\n",
            "Cost after iteration 3500: 0.008341562934219837\n",
            "Iterations: 3500\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.9759167\n",
            "Cost after iteration 3600: 0.007545309141278267\n",
            "Iterations: 3600\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.978\n",
            "Cost after iteration 3700: 0.06609075516462326\n",
            "Iterations: 3700\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.81806666\n",
            "Cost after iteration 3800: 0.01009305752813816\n",
            "Iterations: 3800\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.9706667\n",
            "Cost after iteration 3900: 0.008084339089691639\n",
            "Iterations: 3900\n",
            "[3 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.9766167\n",
            "Cost after iteration 4000: 0.006881305482238531\n",
            "Iterations: 4000\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.9803333\n",
            "Cost after iteration 4100: 0.006114719435572624\n",
            "Iterations: 4100\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.9825167\n",
            "Cost after iteration 4200: 0.005720308516174555\n",
            "Iterations: 4200\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.9838334\n",
            "Cost after iteration 4300: 0.006569626275449991\n",
            "Iterations: 4300\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.98005\n",
            "Cost after iteration 4400: 0.009280665777623653\n",
            "Iterations: 4400\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.97285\n",
            "Cost after iteration 4500: 0.006807321682572365\n",
            "Iterations: 4500\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.98075\n",
            "Cost after iteration 4600: 0.0057688080705702305\n",
            "Iterations: 4600\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.98401666\n",
            "Cost after iteration 4700: 0.005350207444280386\n",
            "Iterations: 4700\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.9850167\n",
            "Cost after iteration 4800: 0.004721870645880699\n",
            "Iterations: 4800\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.98745\n",
            "Cost after iteration 4900: 0.004272975958883762\n",
            "Iterations: 4900\n",
            "[5 0 4 ... 5 6 8] [[5 0 4 ... 5 6 8]]\n",
            "Accuracy  :0.98905003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z1, A1, Z2, A2, Z3, A3, Z4, A4 = forward_propagation(parameters, X_test)\n",
        "predictions = get_predictions(A4)\n",
        "print(\"Accuracy  :\" + str(get_accuracy(predictions, Y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAZDkuOmfQrf",
        "outputId": "0b94fe64-f07a-4c74-d9ff-8119000c46d6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 2 1 ... 4 5 6] [[7 2 1 ... 4 5 6]]\n",
            "Accuracy  :0.96970004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "58DHK1SIKvwg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}